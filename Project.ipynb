{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbdb7e28-2a4a-4fb2-a041-b04f849b1da6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Project outlines:\n",
    "0. Explenation of the project and assumptions made\n",
    "1. Initialize\n",
    "2. Upload the data\n",
    "3. Statistics on the data\n",
    "4. Merge given and enrichment data\n",
    "5. Find length of 'about' section\n",
    "6. Find keywords for the 'about' section\n",
    "7. Use the Gemeni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5670beb2-f0bb-4291-81fd-20871e318473",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 0. Explenation of the project and assumptions made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "995cf982-b632-41c9-aa2b-074870bb346d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Our project aims to develop an AI-driven tool that improves users' \"about\" sections by providing recommendations on length, suggesting personalized keywords, and use the Gemini LLM to make the section more appealing. Essentially, the tool enhances end-user profiles. Our research focuses on optimize the about section using the length of the \"about\" section, the keywords we use in the \"about\" section, and LLm model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f1abc28-1c8e-4ffb-acbd-c50ffe42530b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We hold few assumptions:\n",
    "1. There are not \"spam users\" - all the users in the given LinkedIn profiles dataset are real users that try to get job.\n",
    "2. The \"about\" section for each user has not changed over time, i.e. it is not possible that user changed his \"about\" section after finding a job (or alternativly has changed his \"about\" section after some time in which he has not found job).\n",
    "3. The trend of \"Job-Hopping\" is active*, meaning that the users in the dataset are not necessarily looking for stability in their workplace, but jumping from one job to another.\n",
    "4. No one want to hire users with nothing impressing about them that went through a lot of jobs, as that might indicate that the same users were bad employees that get fired. \n",
    "5. When we say number of jobs we mean number of elements in the *\"experience\"* section, as we interested in people that got job in company they was not part of, and not people that got promotion or did career change inside the company they worked in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f433113a-b4de-4ad7-9fdb-5cd7b8f38b0e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "From assumption 1, we conclude that are statistics about the amount of jobs that people had are valid, as there are not reduntant users that bias the calculations.\\\n",
    "Using assumption 2, we can use assume that the \"about\" section is informative for our project, as it is not changed during the user \"life-span\" in the LinkedIn platform.\\\n",
    "Combining assumptions 3 and 4 let us assume that user seek to get more jobs, as the more jobs a user had the better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca114ad6-0067-4f17-8e78-dccb59fc8c57",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "*about the trend \"Job-Hopping\" you can see the following:\n",
    "1. [Millennials: The Job-Hopping Generation](https://www.gallup.com/workplace/231587/millennials-job-hopping-generation.aspx)\n",
    "2. [Article from Globes about this topic (from 2001!)](https://www.globes.co.il/news/article.aspx?did=524717)\n",
    "\n",
    "From 2 we can conclude that our assumption is valid, as stated there that six in 10 millennials are open to new job opportunities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3626429a-ced2-47a3-a325-47ac85f2d619",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 1. Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "ecf95b09-1981-440f-924b-d66a712f4886",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting langchain_google_genai\n  Downloading langchain_google_genai-1.0.2-py3-none-any.whl (28 kB)\nCollecting langchain-core<0.2,>=0.1.27\n  Downloading langchain_core-0.1.42-py3-none-any.whl (287 kB)\nCollecting google-generativeai<0.6.0,>=0.5.0\n  Downloading google_generativeai-0.5.0-py3-none-any.whl (142 kB)\nRequirement already satisfied: protobuf in /databricks/python3/lib/python3.9/site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain_google_genai) (4.21.5)\nCollecting google-ai-generativelanguage==0.6.1\n  Downloading google_ai_generativelanguage-0.6.1-py3-none-any.whl (663 kB)\nRequirement already satisfied: pydantic in /databricks/python3/lib/python3.9/site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain_google_genai) (2.7.0)\nCollecting google-api-python-client\n  Downloading google_api_python_client-2.125.0-py2.py3-none-any.whl (12.5 MB)\nCollecting google-auth>=2.15.0\n  Downloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\nRequirement already satisfied: typing-extensions in /databricks/python3/lib/python3.9/site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain_google_genai) (4.11.0)\nCollecting google-api-core\n  Downloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.9/site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain_google_genai) (4.66.2)\nCollecting proto-plus<2.0.0dev,>=1.22.3\n  Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\nCollecting protobuf\n  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\nCollecting googleapis-common-protos<2.0.dev0,>=1.56.2\n  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\nRequirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /databricks/python3/lib/python3.9/site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain_google_genai) (2.26.0)\nCollecting grpcio-status<2.0.dev0,>=1.33.2\n  Downloading grpcio_status-1.62.1-py3-none-any.whl (14 kB)\nCollecting grpcio<2.0dev,>=1.33.2\n  Downloading grpcio-1.62.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\nCollecting rsa<5,>=3.1.4\n  Downloading rsa-4.9-py3-none-any.whl (34 kB)\nCollecting cachetools<6.0,>=2.0.0\n  Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\nCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\nCollecting tenacity<9.0.0,>=8.1.0\n  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\nCollecting PyYAML>=5.3\n  Downloading PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\nCollecting packaging<24.0,>=23.2\n  Downloading packaging-23.2-py3-none-any.whl (53 kB)\nCollecting jsonpatch<2.0,>=1.33\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nCollecting langsmith<0.2.0,>=0.1.0\n  Downloading langsmith-0.1.45-py3-none-any.whl (104 kB)\nCollecting jsonpointer>=1.9\n  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\nCollecting orjson<4.0.0,>=3.9.14\n  Downloading orjson-3.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\nCollecting pyasn1<0.7.0,>=0.4.6\n  Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\nRequirement already satisfied: annotated-types>=0.4.0 in /databricks/python3/lib/python3.9/site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.0->langchain_google_genai) (0.6.0)\nRequirement already satisfied: pydantic-core==2.18.1 in /databricks/python3/lib/python3.9/site-packages (from pydantic->google-generativeai<0.6.0,>=0.5.0->langchain_google_genai) (2.18.1)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain_google_genai) (3.2)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain_google_genai) (2.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain_google_genai) (1.26.7)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain_google_genai) (2021.10.8)\nCollecting httplib2<1.dev0,>=0.19.0\n  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\nCollecting uritemplate<5,>=3.0.1\n  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\nCollecting google-auth-httplib2<1.0.0,>=0.2.0\n  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /databricks/python3/lib/python3.9/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.0->langchain_google_genai) (3.0.4)\nInstalling collected packages: pyasn1, rsa, pyasn1-modules, protobuf, cachetools, proto-plus, grpcio, googleapis-common-protos, google-auth, httplib2, grpcio-status, google-api-core, uritemplate, orjson, jsonpointer, google-auth-httplib2, tenacity, PyYAML, packaging, langsmith, jsonpatch, google-api-python-client, google-ai-generativelanguage, langchain-core, google-generativeai, langchain-google-genai\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 4.21.5\n    Not uninstalling protobuf at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-880d14a8-4ae8-4948-87f9-e8839c0dea39\n    Can't uninstall 'protobuf'. No files were found to uninstall.\n  Attempting uninstall: tenacity\n    Found existing installation: tenacity 8.0.1\n    Not uninstalling tenacity at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-880d14a8-4ae8-4948-87f9-e8839c0dea39\n    Can't uninstall 'tenacity'. No files were found to uninstall.\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.0\n    Not uninstalling packaging at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-880d14a8-4ae8-4948-87f9-e8839c0dea39\n    Can't uninstall 'packaging'. No files were found to uninstall.\nSuccessfully installed PyYAML-6.0.1 cachetools-5.3.3 google-ai-generativelanguage-0.6.1 google-api-core-2.18.0 google-api-python-client-2.125.0 google-auth-2.29.0 google-auth-httplib2-0.2.0 google-generativeai-0.5.0 googleapis-common-protos-1.63.0 grpcio-1.62.1 grpcio-status-1.62.1 httplib2-0.22.0 jsonpatch-1.33 jsonpointer-2.4 langchain-core-0.1.42 langchain-google-genai-1.0.2 langsmith-0.1.45 orjson-3.10.0 packaging-23.2 proto-plus-1.23.0 protobuf-4.25.3 pyasn1-0.6.0 pyasn1-modules-0.4.0 rsa-4.9 tenacity-8.2.3 uritemplate-4.1.1\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c13282f0-b0dd-4d9d-97b1-a2ac4639368a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import length\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, explode, collect_list, struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c476fb4-2be9-4834-820d-ba39c10a03f6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 2. Upload the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a80fa93-64f4-4535-96df-ee8486162fd4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Uploading the given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63fa55c9-09af-4c5a-a91c-54e5a2e56b9d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profiles = spark.read.parquet('/linkedin/people')\n",
    "companies = spark.read.parquet('/linkedin/companies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70babc54-6ce6-417e-b316-d6a82dbe8769",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Uploading the enrichment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a0fc92e-0795-4f02-9df7-99fc572c2667",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# !pip install kaggle\n",
    "# api_token = {\"username\":\"itayfk\",\"key\":\"9ee7fc7bb855f54f85affd4302f7682e\"}\n",
    "# import json\n",
    "# import zipfile\n",
    "# import os\n",
    "# with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
    "#     json.dump(api_token, file)\n",
    "# !chmod 600 /root/.kaggle/kaggle.json\n",
    "# import kaggle\n",
    "# from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "# api = KaggleApi()\n",
    "# api.authenticate()\n",
    "# api.get_config_value(\"itayfk\")\n",
    "# api.data_download_file(\"manishkumar7432698/linkedinuserprofiles\", file_name=\"LinkedIn company information datasets (Public web data).csv\")\n",
    "# !kaggle datasets download -d manishkumar7432698/linkedinuserprofiles/LinkedIn company information datasets \"(\"Public web data\")\".csv\n",
    "# api.dataset_download_files(\"manishkumar7432698/linkedinuserprofiles\", \"/Workspace/Users/ido.iutcu@campus.technion.ac.il\", unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56ae82ec-8a8e-4c26-a659-2500a7e50e4e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "enrich_profiles = pd.read_csv(\"/Workspace/Users/ido.iutcu@campus.technion.ac.il/LinkedIn people profiles datasets.csv\")\n",
    "# Convert enrich_profiles DataFrame to PySpark table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d67292c0-856b-43f4-a502-a99d38983c70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "enrich_companies = pd.read_csv(\"/Workspace/Users/ido.iutcu@campus.technion.ac.il/LinkedIn company information datasets (Public web data).csv\")\n",
    "# enrich_companies.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a38df00-c9ac-4abd-beee-cc3351c6fe5e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 3. Statistics on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71e3960e-d5ff-4d4c-bbfb-b96d20b51ccf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Taking a look at the data\n",
    "Print the data scheme, and some important statistics about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b137669-e160-4dff-a572-5f37a6afacd6",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# profiles.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed630e3f-9781-4754-9a03-a9a0a072e5c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Print statistics about profiles\n",
    "total_num_profiles = profiles.count()\n",
    "num_profiles_with = profiles.filter(\"about is not null\").count()\n",
    "num_seekjob_profiles = profiles.filter(\"current_company.company_id is null\").count()\n",
    "num_seekjob_profiles_with = profiles.filter(\"about is not null AND current_company.company_id is null\").count()\n",
    "num_seekjob_profiles_without = profiles.filter(\"about is null AND current_company.company_id is null\").count()\n",
    "\n",
    "# Print statistics about companies data\n",
    "# print(\"Number of companies:\", companies.count())\n",
    "# print(\"Number of unique industries in companies:\", companies.select(\"industries\").distinct().count())\n",
    "# print(\"Number of companies with more than 100 employees:\", companies.filter(\"num_employees > 100\").count())\n",
    "# print(\"Number of companies founded before 2000:\", companies.filter(\"founding_year < 2000\").count())\n",
    "# print(\"Number of companies with IPO:\", companies.filter(\"ipo_date is not null\").count())\n",
    "\n",
    "# Print statistics about profiles data\n",
    "# print(\"Number of profiles:\", total_num_profiles)\n",
    "# print(\"Number of profiles with an about specified:\", num_profiles_with)\n",
    "# print(\"Percentage of profiles with an about specified:\", num_profiles_with / total_num_profiles)\n",
    "# print(\"Number of profiles seeking for a job:\", num_seekjob_profiles)\n",
    "# print(\"Percentage of profiles seeking for a job:\", num_seekjob_profiles / total_num_profiles)\n",
    "# print(\"Percentage of profiles with an about specified seeking for a job:\", num_seekjob_profiles_with / num_profiles_with)\n",
    "# print(\"Percentage of profiles without an about specified seeking for a job:\", num_seekjob_profiles_without / (total_num_profiles-num_profiles_with))\n",
    "# print(\"Number of profiles with an experience specified:\", profiles.filter(\"experience is not null\").count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be342453-d554-4203-ab8d-5ddada78ed7b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We can see clearly that users with something in their *\"about\"* section tend to successfully hold more jobs than the ones who has nothing write in their *\"about\"* section.\\\n",
    "Lets devide the profiles table into two tables - one for users whom have \"about\" section (i.e. not null), and one for users that don't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e65ee73-2780-4fe5-a18c-3cbf2f62f92d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Next, we will check the average number of different jobs that user has held - one for the profiles_with_about table and one for the profiles_without_about table.\\\n",
    "Note that we look at the number of elements in Experience, as we are interested in how many jobs the user held in different companies, not in the same one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94960644-be14-4103-9952-93a7cd884a8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profiles_with_about = profiles.filter(\"about is not null\")\n",
    "profiles_without_about = profiles.filter(\"about is null\")\n",
    "\n",
    "avg_positions_held = profiles.selectExpr(\"avg(size(Experience)) as avg_positions_held\").collect()[0][0]\n",
    "avg_positions_held_with = profiles_with_about.selectExpr(\"avg(size(Experience)) as avg_positions_held_with\").collect()[0][0]\n",
    "avg_positions_held_without = profiles_without_about.selectExpr(\"avg(size(Experience)) as avg_positions_held_without\").collect()[0][0]\n",
    "\n",
    "# print(\"Average number of different jobs that user has held:\", avg_positions_held)\n",
    "# print(\"Average number of different jobs that user with about section has held:\", avg_positions_held_with)\n",
    "# print(\"Average number of different jobs that user without about section has held:\", avg_positions_held_without)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b1ed90a-3200-4c5b-b1d3-537c8664f90c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Thus, it is clear that users with nothing in their *\"about\"* section are expected to hold less jobs than users with something in their *\"about\"* section.\\\n",
    "Next, we will try to explore if it seems that there is any relation between the length of the about section and the number of jobs a user held."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a0b5c23-7de8-44eb-9679-02c508ca5f92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of the lengths of the \"about\" section\n",
    "about_lengths = profiles_with_about.selectExpr(\"length(about) as about_length\").collect()\n",
    "about_lengths = [row.about_length for row in about_lengths]\n",
    "\n",
    "# Create a list of the size(Experience)\n",
    "experience_sizes = profiles_with_about.selectExpr(\"size(Experience) as experience_size\").collect()\n",
    "experience_sizes = [row.experience_size for row in experience_sizes]\n",
    "\n",
    "# Define the bin intervals for the about lengths\n",
    "bin_intervals = np.arange(0, np.max(about_lengths) + 250, 250)\n",
    "\n",
    "# Group the experience sizes based on the intervals\n",
    "grouped_experience_sizes = [np.mean([experience_sizes[j] for j in range(len(about_lengths)) if bin_intervals[i] <= about_lengths[j] < bin_intervals[i+1]]) \n",
    "                            for i in range(len(bin_intervals)-1)]\n",
    "\n",
    "# Plotting the bar chart\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.bar(bin_intervals[:-1], grouped_experience_sizes, width=240, color='skyblue')\n",
    "# plt.title('Experience Sizes vs About Lengths')\n",
    "# plt.xlabel('About Lengths (in intervals of 250)')\n",
    "# plt.ylabel('Average Experience Sizes')\n",
    "# plt.grid(axis='y')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "474ae080-9321-4b0b-9333-b35cf892b4fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Above we can see another interesting insight, it seems that the average number of jobs is monotone increasing as function of the length of the *\"about\"* section, i.e. the longer the *\"about\"* section, the more jobs you held in average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aadcd95-04a7-4041-8c2b-24b3f2dfc41e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Lets also check if there is a connection between the average number of jobs and the length of the 'about' section inside individual industries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17adc3d1-bfb4-4c63-ba1b-7d5c71c01654",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "only_id_industry_companies = companies.select(col(\"id\"), col(\"industries\"))\n",
    "\n",
    "# Join the profiles_with_about and companies DataFrames\n",
    "profiles_with_about_ind = profiles_with_about.join(only_id_industry_companies, profiles_with_about[\"current_company.company_id\"] == only_id_industry_companies[\"id\"], \"left\")\n",
    "# profiles_with_about_ind.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45e361c9-de51-4e5d-aa81-4a1e27dd4489",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profiles_with_about_ind_extract = profiles_with_about_ind.select(col(\"about\"), col(\"industries\"))\n",
    "profiles_with_about_ind_extract = profiles_with_about_ind_extract.filter(\"industries is not null\")\n",
    "\n",
    "profiles_with_about_ind_exp_extract = profiles_with_about_ind.select(col(\"about\"), col(\"industries\"), col(\"experience\"))\n",
    "profiles_with_about_ind_exp_extract = profiles_with_about_ind_exp_extract.filter(\"industries is not null\")\n",
    "\n",
    "# Group by industries and count\n",
    "top10_industries = profiles_with_about_ind_extract.groupBy(\"industries\").count()\n",
    "\n",
    "# Sort by count in descending order\n",
    "top10_industries = top10_industries.orderBy(\"count\", ascending=False)\n",
    "\n",
    "# Select top 10 industries\n",
    "top10_industries = top10_industries.limit(10)\n",
    "\n",
    "# Display the result\n",
    "# top10_industries.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64d688b2-9ffa-432e-a083-84916c9d8965",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of top 10 industries\n",
    "top10_industries_list = top10_industries.select(\"industries\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Filter rows in profiles_with_about_ind_extract where industry is in top 10 industries list\n",
    "filtered_profiles = profiles_with_about_ind_extract.filter(profiles_with_about_ind_extract.industries.isin(top10_industries_list))\n",
    "\n",
    "# Convert the \"about\" column into its length\n",
    "filtered_profiles = filtered_profiles.withColumn(\"about_length\", length(filtered_profiles.about))\n",
    "filtered_profiles = filtered_profiles.select(col(\"about_length\"), col(\"industries\"))\n",
    "\n",
    "# Group the data by the \"industry\" column and calculate the average length of the \"about\" section\n",
    "avg_about_length_by_industry = filtered_profiles.groupby(\"industries\").agg({\"about_length\": \"avg\"})\n",
    "\n",
    "# Convert the DataFrame to Pandas for easier plotting\n",
    "avg_about_length_by_industry_pd = avg_about_length_by_industry.toPandas()\n",
    "\n",
    "# Plotting the bar chart\n",
    "# plt.figure(figsize=(15, 9))\n",
    "# plt.bar(avg_about_length_by_industry_pd[\"industries\"], avg_about_length_by_industry_pd[\"avg(about_length)\"], color='skyblue')\n",
    "# plt.title('Average Length of About Section by Industry')\n",
    "# plt.xlabel('Industry')\n",
    "# plt.ylabel('Average Length of About Section')\n",
    "# plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "# plt.grid(axis='y')  # Add gridlines only along the y-axis\n",
    "# plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8aa2571-a572-4abf-81c6-4027a5c4a84f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "From the bar plot above we can conclude that trying to make your *\"about\"* section longer is not always the right choice, and therefore out task of finding a custom length for each user in LinkedIn is indeed real task, with no simple solution such as to make the *\"about\"* section as long as you can.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36afa04c-e1bc-4422-8434-07186f3b8d38",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Next, we will look at the experience sizes vs about lengths per industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bd6ad88-c2fa-4d3e-a2e8-77eb21c2a714",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def hist_by_ind(industry):\n",
    "    # Select all rows where the industry is Real Estate from profiles_with_about_ind_exp_extract\n",
    "    selected_industry_profiles = profiles_with_about_ind_exp_extract.filter(profiles_with_about_ind_exp_extract.industries == industry)\n",
    "\n",
    "    # Create a list of the lengths of the \"about\" section\n",
    "    about_lengths = selected_industry_profiles.selectExpr(\"length(about) as about_length\").collect()\n",
    "    about_lengths = [row.about_length for row in about_lengths]\n",
    "\n",
    "    # Create a list of the size(Experience)\n",
    "    experience_sizes = selected_industry_profiles.selectExpr(\"size(Experience) as experience_size\").collect()\n",
    "    experience_sizes = [row.experience_size for row in experience_sizes]\n",
    "\n",
    "    # Define the bin intervals for the about lengths\n",
    "    bin_intervals = np.arange(0, np.max(about_lengths) + 250, 250)\n",
    "\n",
    "    # Group the experience sizes based on the intervals\n",
    "    grouped_experience_sizes = [np.mean([experience_sizes[j] for j in range(len(about_lengths)) if bin_intervals[i] <= about_lengths[j] < bin_intervals[i+1]]) \n",
    "                                for i in range(len(bin_intervals)-1)]\n",
    "\n",
    "    # Plotting the bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(bin_intervals[:-1], grouped_experience_sizes, width=240, color='skyblue')\n",
    "    plt.title(f'Experience Sizes vs About Lengths in industry {industry}')\n",
    "    plt.xlabel('About Lengths (in intervals of 250)')\n",
    "    plt.ylabel('Average Experience Sizes')\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5433550e-d8ed-4ba8-b287-79453b5fc078",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# hist_by_ind(\"Real Estate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a4e2d28-7cb0-4846-abaf-4c0e09b96333",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# hist_by_ind(\"Higher Education\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89d4898d-8aa6-438e-a7df-74ec7de692bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# hist_by_ind(\"Hospitals and Health Care\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2fd87df-2087-416c-8f16-32c03b76bad5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# hist_by_ind(\"IT Services and IT Consulting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dd06dfb-aaa7-40d3-8478-4b48b50df021",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# hist_by_ind(\"Retail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0df1fa8f-96f8-41b7-958f-9e9ae1def5eb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As we can see from the 5 histograms above, for the each of the largest 5 industries there is different length of 'about' section that is the best.\n",
    "\n",
    "Therefore, it is indeed good idea to try and find the optimal length of the 'about' section for each profile. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32eee442-001b-46ce-87de-9a5bb1ef31bb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 4. Merge given and enrichment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "713864e2-bfd7-4a7d-ab93-80e8fba23252",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 4.1 Extract the features for the Regression Tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "721a8665-d830-4a1f-aaf6-fea374c03974",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 4.1.1 From given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76c0e8f3-24dc-47a0-b905-f96dd6b34605",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "only_id_industry_companies = companies.select(col(\"id\"), col(\"industries\"))\n",
    "\n",
    "# Join the profiles_with_about and companies DataFrames\n",
    "profiles_with_about_ind = profiles_with_about.join(only_id_industry_companies, profiles_with_about[\"current_company.company_id\"] == only_id_industry_companies[\"id\"], \"left\")\n",
    "\n",
    "profiles_for_fakti = profiles_with_about_ind.select(col(\"about\"), col(\"education\"), col(\"certifications\"), col(\"volunteer_experience\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75782b9b-4b2e-4a38-b28a-65a167784b4a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 4.1.2 From enrichment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4fece86-ffac-4cc8-a3f6-68da5ab9cc94",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "enrich_profiles = enrich_profiles[[\"name\", \"about\", \"experience\", \"education\", \"certifications\", \"recommendations\", \"volunteer_experience\"]]\n",
    "\n",
    "# Convert pandas dataframe to pyspark dataframe\n",
    "enrich_profiles_spark = spark.createDataFrame(enrich_profiles)\n",
    "\n",
    "# Remove rows with null values\n",
    "enrich_profiles_spark = enrich_profiles_spark.dropna()\n",
    "\n",
    "experience_struct_type = StructType([\n",
    "    StructField(\"company\", StringType()),\n",
    "    StructField(\"company_id\", StringType()),\n",
    "    StructField(\"industry\", StringType()),\n",
    "    StructField(\"location\", StringType()),\n",
    "    StructField(\"positions\", ArrayType(StructType([\n",
    "        StructField(\"description\", StringType()),\n",
    "        StructField(\"duration\", StringType()),\n",
    "        StructField(\"duration_short\", StringType()),\n",
    "        StructField(\"end_date\", StringType()),\n",
    "        StructField(\"start_date\", StringType()),\n",
    "        StructField(\"subtitle\", StringType()),\n",
    "        StructField(\"title\", StringType())\n",
    "    ]))),\n",
    "    StructField(\"url\", StringType())\n",
    "])\n",
    "\n",
    "education_struct_type = StructType([\n",
    "    StructField(\"degree\", StringType()),\n",
    "    StructField(\"end_year\", StringType()),\n",
    "    StructField(\"field\", StringType(), nullable=True),\n",
    "    StructField(\"meta\", StringType()),\n",
    "    StructField(\"start_year\", StringType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"url\", StringType())\n",
    "])\n",
    "\n",
    "certifications_struct_type = StructType([\n",
    "    StructField(\"meta\", StringType()),\n",
    "    StructField(\"subtitle\", StringType()),\n",
    "    StructField(\"title\", StringType())\n",
    "])\n",
    "\n",
    "# certifications_struct_type = StructType([\n",
    "#     StructField(\"meta\", StringType()),\n",
    "#     StructField(\"subtitle\", StringType()),\n",
    "#     StructField(\"title\", StringType())\n",
    "# ])\n",
    "\n",
    "volunteer_experience_struct_type = StructType([\n",
    "    StructField(\"cause\", StringType()),\n",
    "    StructField(\"duration\", StringType()),\n",
    "    StructField(\"duration_short\", StringType()),\n",
    "    StructField(\"end_date\", StringType()),\n",
    "    StructField(\"info\", StringType()),\n",
    "    StructField(\"start_date\", StringType()),\n",
    "    StructField(\"subtitle\", StringType()),\n",
    "    StructField(\"title\", StringType())\n",
    "])\n",
    "\n",
    "# Define a UDF to apply json.loads\n",
    "def parse_json(s):\n",
    "    return json.loads(s)\n",
    "\n",
    "# Register the UDF\n",
    "experience_parse_json_udf = udf(parse_json,ArrayType(experience_struct_type))\n",
    "# Apply the UDF to the column\n",
    "enrich_profiles_spark = enrich_profiles_spark.withColumn(\"experience_\", experience_parse_json_udf(col(\"experience\")))\n",
    "\n",
    "# Register the UDF\n",
    "certifications_parse_json_udf = udf(parse_json,ArrayType(certifications_struct_type))\n",
    "# Apply the UDF to the column\n",
    "enrich_profiles_spark = enrich_profiles_spark.withColumn(\"certifications_\", certifications_parse_json_udf(col(\"certifications\")))\n",
    "\n",
    "# Register the UDF\n",
    "education_parse_json_udf = udf(parse_json,ArrayType(education_struct_type))\n",
    "# Apply the UDF to the column\n",
    "enrich_profiles_spark = enrich_profiles_spark.withColumn(\"education_\", education_parse_json_udf(col(\"education\")))\n",
    "\n",
    "# # Register the UDF\n",
    "# recommendations_parse_json_udf = udf(parse_json,ArrayType(recommendations_struct_type))\n",
    "# # Apply the UDF to the column\n",
    "# enrich_profiles_spark = enrich_profiles_spark.withColumn(\"recommendations_\", recommendations_parse_json_udf(col(\"recommendations\")))\n",
    "\n",
    "# Register the UDF\n",
    "volunteer_experience_parse_json_udf = udf(parse_json,ArrayType(volunteer_experience_struct_type))\n",
    "# Apply the UDF to the column\n",
    "enrich_profiles_spark = enrich_profiles_spark.withColumn(\"volunteer_experience_\", volunteer_experience_parse_json_udf(col(\"volunteer_experience\")))\n",
    "\n",
    "enrich_profiles_spark = enrich_profiles_spark.drop(\"experience\", \"experience_\", \"education\", \"certifications\", \"recommendations\", \"volunteer_experience\")\n",
    "\n",
    "enrich_profiles_spark = enrich_profiles_spark \\\n",
    "    .withColumnRenamed(\"education_\", \"education\") \\\n",
    "    .withColumnRenamed(\"certifications_\", \"certifications\") \\\n",
    "    .withColumnRenamed(\"volunteer_experience_\", \"volunteer_experience\")\n",
    "\n",
    "enrich_profiles_spark = enrich_profiles_spark.select(col(\"about\"), col(\"education\"), col(\"certifications\"), col(\"volunteer_experience\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4889e17-6d38-4c9d-b3b2-e661ebdf04b8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 4.2 Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b33c0fe4-67ad-4bd3-8a8c-93fc796edd5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merge_profiles1 = profiles_for_fakti\n",
    "merge_profiles2 = enrich_profiles_spark\n",
    "\n",
    "merged_profiles = merge_profiles1.union(merge_profiles2)\n",
    "features_for_rt = merged_profiles\n",
    "# features_for_rt.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2aa411f2-e7e3-45e0-ac1e-f745edc0af3f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 4.3 Remove empty elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08afaa6b-6350-4305-a0e4-e8e60ba14d54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import size\n",
    "\n",
    "features_for_rt = features_for_rt.where(size(features_for_rt.education) > 0)\n",
    "features_for_rt = features_for_rt.where(size(features_for_rt.certifications) > 0)\n",
    "features_for_rt = features_for_rt.where(size(features_for_rt.volunteer_experience) > 0)\n",
    "\n",
    "# features_for_rt.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d90a14a9-6bbf-44eb-87d3-0ace013ac103",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 5. Find length of 'about' section\n",
    "\n",
    "We will find the optimal length of 'about' section using Regression Tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79206587-1695-4794-b840-9f7b63166c5c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 5.1 First try - Regression Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d1fa849-36fb-4a6d-8c11-e4489f01f830",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Training Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecfa3519-3a25-4681-9ec7-17961edcd0bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_subtitle_str(arr):\n",
    "    return ' '.join([d[\"subtitle\"] if isinstance(d[\"subtitle\"], str) else \"\" for d in arr]) + \" |\"\n",
    "\n",
    "def get_title_str(arr):\n",
    "    return ' '.join([d[\"title\"] if isinstance(d[\"title\"], str) else \"\" for d in arr]) + \" |\"\n",
    "\n",
    "def get_num_of_words(string):\n",
    "    return len(list(string.split(\" \")))\n",
    "\n",
    "udf_dict_to_string_subtitle = udf(get_subtitle_str, StringType())\n",
    "udf_dict_to_string_title = udf(get_title_str, StringType())\n",
    "udf_about_num_of_words =  udf(get_num_of_words, IntegerType())\n",
    "# udf_dict_to_string_education = udf(education_dict_to_str, StringType())\n",
    "df_fakter = features_for_rt.withColumn(\"certificationString\", udf_dict_to_string_subtitle(features_for_rt[\"certifications\"]))\n",
    "# df_fakter = df_fakter.withColumn(\"educationString\", udf_dict_to_string_education(df_fakter[\"education\"]))\n",
    "df_fakter = df_fakter.withColumn(\"volunteerString\", udf_dict_to_string_title(df_fakter[\n",
    "\"volunteer_experience\"]))\n",
    "columns_to_concat = [\"certificationString\", \"volunteerString\"]\n",
    "df_concatenated = df_fakter.withColumn(\"all_text\", F.concat_ws(\" \", *[F.when(F.col(c).isNull(), F.lit(\"none\")).otherwise(F.col(c)) for c in columns_to_concat]))\n",
    "df_just_txt = df_concatenated.select(\"all_text\", \"about\")\n",
    "df_just_txt = df_just_txt.withColumn(\"target\", udf_about_num_of_words(df_just_txt[\"about\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3342524-4b09-434e-a538-1586fa7f735e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_small_bert_L2_128 download started this may take some time.\nApproximate size to download 16.1 MB\n\r[ | ]\r[ / ]\r[  ]\r[ \\ ]\r[ | ]\r[OK!]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import IndexToString\n",
    "from pyspark.ml import Pipeline\n",
    "from sparknlp.annotator import BertSentenceEmbeddings\n",
    "from sparknlp.base import DocumentAssembler\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "documentAssembler_4 = DocumentAssembler().setInputCol(\"all_text\").setOutputCol(\"doc\")\n",
    "sentence_4 = SentenceDetector() \\\n",
    "    .setInputCols([\"doc\"]) \\\n",
    "    .setOutputCol(\"sentence\") \\\n",
    "    .setCustomBounds([\"^KOPER^\"]) \\\n",
    "    .setUseCustomBoundsOnly(True)\n",
    "embeddings_4 = BertSentenceEmbeddings.pretrained(\"sent_small_bert_L2_128\", \"en\") \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"bert_embeddings\")\n",
    "embeddingsFinisher_4 = EmbeddingsFinisher() \\\n",
    "    .setInputCols([\"bert_embeddings\"]) \\\n",
    "    .setOutputCols(\"finished_embeddings\") \\\n",
    "    .setOutputAsVector(True)\n",
    "pipeline_4 = Pipeline().setStages([documentAssembler_4, sentence_4 ,embeddings_4,embeddingsFinisher_4]).fit(df_just_txt)\n",
    "df_tokenized = pipeline_4.transform(df_just_txt)\n",
    "df_tokenized_toModel = df_tokenized.select(\"target\", \"finished_embeddings\")\n",
    "\n",
    "# Define a UDF to extract \"values\" property from each element\n",
    "def extract_values(embeddings):\n",
    "    return embeddings[0].toArray().tolist()\n",
    "\n",
    "# Register the UDF\n",
    "extract_values_udf = udf(extract_values, ArrayType(DoubleType()))\n",
    "df_ready = df_tokenized_toModel.withColumn(\"values\", extract_values_udf(df_tokenized_toModel[\"finished_embeddings\"]))\n",
    "df_ready = df_ready.select([\"target\", \"values\"])\n",
    "list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "df_ready = df_ready.withColumn(\"features\", list_to_vector_udf(\"values\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a99de5b8-3d8c-425b-8ced-e96805d885b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train:\n55.1913282546854\nRMSE test:\n100.2113530333003\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "train_set, test_set = df_ready.randomSplit([0.8,0.2], seed=42)\n",
    "rt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"target\", maxDepth=16)\n",
    "rtModel = rt.fit(train_set)\n",
    "train_preds = rtModel.transform(train_set)\n",
    "evaluator_train = RegressionEvaluator(labelCol=\"target\", predictionCol=\"prediction\")\n",
    "print(\"RMSE train:\")\n",
    "print(evaluator_train.evaluate(train_preds))\n",
    "evaluator_test = RegressionEvaluator(labelCol=\"target\", predictionCol=\"prediction\")\n",
    "test_preds = rtModel.transform(test_set)\n",
    "print(\"RMSE test:\")\n",
    "print(evaluator_test.evaluate(test_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1309fd56-bbee-4081-baf2-1469fc307448",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 5.2 Second try - Meta Industries\n",
    "We will try and use the mean length of each meta industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62974fd9-784b-44f6-a379-c9ad1e6c27b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "meta_industries_12 = {\n",
    "    'Furniture and Home Furnishings Manufacturing': 'Manufacturing',\n",
    "    'Investment Banking': 'Financial and Investment',\n",
    "    'Architecture and Planning': 'Services',\n",
    "    'Wholesale': 'Services',\n",
    "    'Travel Arrangements': 'Services',\n",
    "    'Ranching': 'Miscellaneous',\n",
    "    'Hospitals and Health Care': 'Healthcare and Medical',\n",
    "    'Book and Periodical Publishing': 'Services',\n",
    "    'Printing Services': 'Services',\n",
    "    'Professional Training and Coaching': 'Services',\n",
    "    'Computers and Electronics Manufacturing': 'Manufacturing',\n",
    "    'Shipbuilding': 'Manufacturing',\n",
    "    'Public Policy Offices': 'Government and Public Policy',\n",
    "    'Software Development': 'Technology',\n",
    "    'Outsourcing and Offshoring Consulting': 'Services',\n",
    "    'Retail Groceries': 'Retail and Consumer Goods',\n",
    "    'Education Administration Programs': 'Education and Training',\n",
    "    'Plastics Manufacturing': 'Manufacturing',\n",
    "    'Renewable Energy Semiconductor Manufacturing': 'Manufacturing',\n",
    "    'Computer Networking Products': 'Technology',\n",
    "    'Events Services': 'Services',\n",
    "    'Information Services': 'Services',\n",
    "    'Food and Beverage Services': 'Services',\n",
    "    'Semiconductor Manufacturing': 'Manufacturing',\n",
    "    'Business Consulting and Services': 'Services',\n",
    "    'Insurance': 'Services',\n",
    "    'Financial Services': 'Services',\n",
    "    'Wireless Services': 'Services',\n",
    "    'Computer Hardware Manufacturing': 'Technology',\n",
    "    'Public Safety': 'Services',\n",
    "    'Maritime Transportation': 'Transportation and Logistics',\n",
    "    'Tobacco Manufacturing': 'Manufacturing',\n",
    "    'Writing and Editing': 'Services',\n",
    "    'Veterinary Services': 'Services',\n",
    "    'Staffing and Recruiting': 'Services',\n",
    "    'Accounting': 'Services',\n",
    "    'International Affairs': 'Government and Public Policy',\n",
    "    'Spectator Sports': 'Miscellaneous',\n",
    "    'Glass, Ceramics and Concrete Manufacturing': 'Manufacturing',\n",
    "    'Chemical Manufacturing': 'Manufacturing',\n",
    "    'Mining': 'Miscellaneous',\n",
    "    'E-Learning Providers': 'Technology',\n",
    "    'Security and Investigations': 'Services',\n",
    "    'Translation and Localization': 'Services',\n",
    "    'Automation Machinery Manufacturing': 'Technology',\n",
    "    'Computer and Network Security': 'Technology',\n",
    "    'Political Organizations': 'Government and Public Policy',\n",
    "    'Environmental Services': 'Government and Public Policy',\n",
    "    'Oil and Gas': 'Miscellaneous',\n",
    "    'Real Estate': 'Real Estate and Construction',\n",
    "    'Think Tanks': 'Government and Public Policy',\n",
    "    'Executive Offices': 'Miscellaneous',\n",
    "    'Law Practice': 'Services',\n",
    "    'Nanotechnology Research': 'Miscellaneous',\n",
    "    'International Trade and Development': 'Government and Public Policy',\n",
    "    'Personal Care Product Manufacturing': 'Manufacturing',\n",
    "    'Philanthropic Fundraising Services': 'Services',\n",
    "    'Entertainment Providers': 'Media and Entertainment',\n",
    "    'Market Research': 'Media and Entertainment',\n",
    "    'Movies, Videos, and Sound': 'Media and Entertainment',\n",
    "    'Sporting Goods Manufacturing': 'Manufacturing',\n",
    "    'Graphic Design': 'Services',\n",
    "    'Technology, Information and Internet': 'Technology',\n",
    "    'IT Services and IT Consulting': 'Technology',\n",
    "    'Retail Office Equipment': 'Retail and Consumer Goods',\n",
    "    'Wholesale Import and Export': 'Services',\n",
    "    'Capital Markets': 'Financial and Investment',\n",
    "    'Law Enforcement': 'Services',\n",
    "    'Freight and Package Transportation': 'Transportation and Logistics',\n",
    "    'Industrial Machinery Manufacturing': 'Manufacturing',\n",
    "    'Non-profit Organizations': 'Miscellaneous',\n",
    "    'Retail Art Supplies': 'Retail and Consumer Goods',\n",
    "    'Animation and Post-production': 'Media and Entertainment',\n",
    "    'Transportation, Logistics, Supply Chain and Storage': 'Transportation and Logistics',\n",
    "    'Aviation and Aerospace Component Manufacturing': 'Transportation and Logistics',\n",
    "    'Fundraising': 'Financial and Investment',\n",
    "    'Railroad Equipment Manufacturing': 'Transportation and Logistics',\n",
    "    'Construction': 'Real Estate and Construction',\n",
    "    'Investment Management': 'Financial and Investment',\n",
    "    'Utilities': 'Miscellaneous',\n",
    "    'Retail Luxury Goods and Jewelry': 'Retail and Consumer Goods',\n",
    "    'Warehousing and Storage': 'Transportation and Logistics',\n",
    "    'Media Production': 'Media and Entertainment',\n",
    "    'Gambling Facilities and Casinos': 'Media and Entertainment',\n",
    "    'Defense and Space Manufacturing': 'Manufacturing',\n",
    "    'Facilities Services': 'Services',\n",
    "    'Government Relations Services': 'Government and Public Policy',\n",
    "    'Advertising Services': 'Media and Entertainment',\n",
    "    'Paper and Forest Product Manufacturing': 'Manufacturing',\n",
    "    'Packaging and Containers Manufacturing': 'Manufacturing',\n",
    "    'Telecommunications': 'Technology',\n",
    "    'Medical Equipment Manufacturing': 'Healthcare and Medical',\n",
    "    'Beverage Manufacturing': 'Manufacturing',\n",
    "    'Restaurants': 'Retail and Consumer Goods',\n",
    "    'Leasing Non-residential Real Estate': 'Real Estate and Construction',\n",
    "    'Newspaper Publishing': 'Media and Entertainment',\n",
    "    'Armed Forces': 'Miscellaneous',\n",
    "    'Appliances, Electrical, and Electronics Manufacturing': 'Manufacturing',\n",
    "    'Hospitality': 'Services',\n",
    "    'Pharmaceutical Manufacturing': 'Healthcare and Medical',\n",
    "    'Research Services': 'Services',\n",
    "    'Retail Apparel and Fashion': 'Retail and Consumer Goods',\n",
    "    'Photography': 'Media and Entertainment',\n",
    "    'Wellness and Fitness Services': 'Services',\n",
    "    'Truck Transportation': 'Transportation and Logistics',\n",
    "    'Consumer Services': 'Services',\n",
    "    'Wholesale Building Materials': 'Services',\n",
    "    'Human Resources Services': 'Services',\n",
    "    'Airlines and Aviation': 'Transportation and Logistics',\n",
    "    'Machinery Manufacturing': 'Manufacturing',\n",
    "    'Individual and Family Services': 'Services',\n",
    "    'Motor Vehicle Manufacturing': 'Manufacturing',\n",
    "    'Performing Arts': 'Media and Entertainment',\n",
    "    'Museums, Historical Sites, and Zoos': 'Media and Entertainment',\n",
    "    'Broadcast Media Production and Distribution': 'Media and Entertainment',\n",
    "    'Banking': 'Financial and Investment',\n",
    "    'Recreational Facilities': 'Miscellaneous',\n",
    "    'Government Administration': 'Government and Public Policy',\n",
    "    'Public Relations and Communications Services': 'Media and Entertainment',\n",
    "    'Fisheries': 'Miscellaneous',\n",
    "    'Medical Practices': 'Healthcare and Medical',\n",
    "    'Religious Institutions': 'Miscellaneous',\n",
    "    'Online Audio and Video Media': 'Media and Entertainment',\n",
    "    'Artists and Writers': 'Miscellaneous',\n",
    "    'Biotechnology Research': 'Healthcare and Medical',\n",
    "    'Legal Services': 'Services',\n",
    "    'Retail': 'Retail and Consumer Goods',\n",
    "    'Civil Engineering': 'Services',\n",
    "    'Libraries': 'Miscellaneous',\n",
    "    'Alternative Dispute Resolution': 'Miscellaneous',\n",
    "    'Manufacturing': 'Miscellaneous',\n",
    "    'Design Services': 'Services',\n",
    "    'Dairy Product Manufacturing': 'Manufacturing',\n",
    "    'Higher Education': 'Education and Training',\n",
    "    'Civic and Social Organizations': 'Miscellaneous',\n",
    "    'Textile Manufacturing': 'Manufacturing',\n",
    "    'Venture Capital and Private Equity Principals': 'Financial and Investment',\n",
    "    'Mental Health Care': 'Healthcare and Medical',\n",
    "    'Musicians': 'Media and Entertainment',\n",
    "    'Farming': 'Miscellaneous',\n",
    "    'Computer Games': 'Media and Entertainment',\n",
    "    'Strategic Management Services': 'Services',\n",
    "    'Food and Beverage Manufacturing': 'Manufacturing',\n",
    "    'Primary and Secondary Education': 'Education and Training',\n",
    "    'Alternative Medicine': 'Healthcare and Medical',\n",
    "    'Legislative Offices': 'Services',\n",
    "    'Administration of Justice': 'Services',\n",
    "    'Mobile Gaming Apps': 'Media and Entertainment'\n",
    "}\n",
    "\n",
    "meta_industry = udf( lambda x: meta_industries_12[x] )\n",
    "profiles_with_about_metaind = profiles_with_about_ind.filter(companies.industries.isNotNull())\n",
    "profiles_with_about_metaind = profiles_with_about_metaind.withColumn('meta_industry', meta_industry(col('industries')))\n",
    "\n",
    "\n",
    "def get_num_of_words(string):\n",
    "    return len(list(string.split(\" \")))\n",
    "\n",
    "udf_about_num_of_words =  udf(get_num_of_words, IntegerType())\n",
    "\n",
    "profiles_with_about_metaind = profiles_with_about_metaind.withColumn(\"target\", udf_about_num_of_words(profiles_with_about_metaind[\"about\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "875f5002-4d79-456a-a711-40a82658e609",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profiles_with_about_metaind_select = profiles_with_about_metaind.select('about', 'meta_industry', 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08d9c7c1-2bf8-42cb-8e8c-440261f6155e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the mean length of the about column for each meta_industry\n",
    "about_length_avg = profiles_with_about_metaind_select.groupBy('meta_industry').agg(avg('target').alias('avg_words_in_about'))\n",
    "# about_length_avg = about_length_avg.join(label_translator, about_length_avg['meta_industry'] == label_translator['meta_industry'])\n",
    "about_length_avg = about_length_avg.select('meta_industry', 'avg_words_in_about')\n",
    "\n",
    "# Convert about_length_avg into dictionary\n",
    "about_length_dict = about_length_avg.rdd.collectAsMap()\n",
    "about_length_dict = {k: int(v) for k, v in about_length_dict.items()}\n",
    "\n",
    "# Print the dictionary\n",
    "# about_length_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d7677cb-9a4e-48c3-bef5-cd7fce6c495e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "about_length_dict_ind = [\n",
    "    77,\n",
    "    82,\n",
    "    71,\n",
    "    70,\n",
    "    71,\n",
    "    75,\n",
    "    82,\n",
    "    83,\n",
    "    86,\n",
    "    88,\n",
    "    73,\n",
    "    77 ]\n",
    "\n",
    "label_translator = {\n",
    "    \"Miscellaneous\": 0,\n",
    "    \"Services\": 1,\n",
    "    \"Transportation and Logistics\": 2,\n",
    "    \"Retail and Consumer Goods\": 3,\n",
    "    \"Healthcare and Medical\": 4,\n",
    "    \"Government and Public Policy\": 5,\n",
    "    \"Education and Training\": 6,\n",
    "    \"Technology\": 7,\n",
    "    \"Real Estate and Construction\": 8,\n",
    "    \"Media and Entertainment\": 9,\n",
    "    \"Manufacturing\": 10,\n",
    "    \"Financial and Investment\": 11\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07d3ac85-0605-4aa2-849e-992665b9b6b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "import numpy as np\n",
    "\n",
    "profiles_with_about_metaind_predicted = profiles_with_about_metaind.select('meta_industry', 'target')\n",
    "\n",
    "lab2idx = udf(lambda x: label_translator[x],IntegerType())\n",
    "profiles_with_about_metaind_predicted = profiles_with_about_metaind_predicted.withColumn(\"meta_industry\", lab2idx(profiles_with_about_metaind_predicted[\"meta_industry\"]))\n",
    "\n",
    "# profiles_with_about_metaind_predicted = profiles_with_about_metaind_predicted.withColumn(\"predicted_target\",MyUDFs.trans(about_length_dict_ind)(profiles_with_about_metaind_predicted[\"meta_industry\"],profiles_with_about_metaind_predicted[\"target\"]))\n",
    "\n",
    "# # Add column named predicted_target based on the value in about_length_dict\n",
    "# # profiles_with_about_metaind_predicted = profiles_with_about_metaind_predicted.withColumn('predicted_target', about_length_dict[col('meta_industry').cast('string')])\n",
    "\n",
    "# profiles_with_about_metaind_predicted.display()\n",
    "\n",
    "# Convert the 'target' column of profiles_with_about_metaind_predicted to a numpy array\n",
    "np_target = np.array(profiles_with_about_metaind_predicted.select('target').collect())\n",
    "\n",
    "# Convert the 'meta_industry' column of profiles_with_about_metaind_predicted to a numpy array\n",
    "np_meta_industry = np.array(profiles_with_about_metaind_predicted.select('meta_industry').collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "423d0ba4-3cdf-4479-b402-e5d086d2c3c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert the 'target' column of profiles_with_about_metaind_predicted to a numpy array\n",
    "np_target = np.array(profiles_with_about_metaind_predicted.select('target').collect())\n",
    "\n",
    "# Convert the 'meta_industry' column of profiles_with_about_metaind_predicted to a numpy array\n",
    "np_meta_industry = np.array(profiles_with_about_metaind_predicted.select('meta_industry').collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93b0b9ce-5e39-426b-9324-21bfd633f3a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 71.50609421921602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create an empty list to store the predicted values\n",
    "predicted_values = []\n",
    "\n",
    "# Loop through each element in np_meta_industry\n",
    "for meta_industry in np_meta_industry:\n",
    "    # Use the about_length_dict to predict the target value\n",
    "    predicted_value = about_length_dict_ind[meta_industry[0]]\n",
    "    predicted_values.append(predicted_value)\n",
    "\n",
    "# Calculate the RMSE using the predicted values and np_target\n",
    "rmse = np.sqrt(mean_squared_error(np_target, predicted_values))\n",
    "\n",
    "# Print the RMSE\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34de0779-8bc3-40c0-b7c2-10d8ead0c67e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We see that the last method is working better and acheiving superior results than the Regression Tree method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe0e3186-9df7-4a78-aa66-1df0469c492e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 6. Find keywords for the 'about' section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a491440a-0b46-4439-b3ca-37033342ea00",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_llm = profiles_with_about_metaind.select(\"name\",\"about\",explode(\"experience\").alias(\"experience_element\"), \"meta_industry\")\n",
    "df_llm = df_llm.withColumn(\"length\", (length(col(\"experience_element.description\")) / 2).cast(\"int\"))\n",
    "\n",
    "def split_description(description, half_length):\n",
    "    if half_length is not None:\n",
    "        return description[:half_length]\n",
    "    return description\n",
    "split_description_udf = F.udf(split_description, StringType())\n",
    "df_llm = df_llm.withColumn(\"description\", split_description_udf(col(\"experience_element.description\"), col(\"length\"))).select(\"name\",\"about\",\"description\", \"meta_industry\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffd3069f-c447-49bd-a818-d2c8cbd33444",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>description</th><th>description_keywords</th><th>metadata</th></tr></thead><tbody><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>Program and operations manager for all TMA services, primarily focused on EZRide Shuttle (fixed route commuter shuttle linking commuter rail terminal and Cambridge worksites, with 2,000-3,000 daily boardings). Also oversee Emergency Ride Home program and commuter information programs. Manage NextBus AVL system for shuttles.</td><td>List(tma services, cambridge worksites, emergency ride, ride home, emergency ride home)</td><td>List(Map(score -> 0.5464460443720845, sentence -> 0), Map(score -> 0.5464460443720845, sentence -> 0), Map(score -> 0.43687228818560925, sentence -> 1), Map(score -> 0.43687228818560925, sentence -> 1), Map(score -> 0.39617831238884077, sentence -> 1))</td></tr><tr><td>Service coordinator for Waltham CitiBus network, as well as other TMA commuter shuttle routes. CitiBus provided fixed-route transit service to parts of Waltham not fully served by the MBTA. Also assisted with management of the Council's other shuttles (Alewife, Needham, and Bentley College).</td><td>List(waltham citibus, tma commuter, bentley college, waltham citibus network, tma commuter shuttle)</td><td>List(Map(score -> 0.6057436402052977, sentence -> 0), Map(score -> 0.5463402994396243, sentence -> 0), Map(score -> 0.5283089023826478, sentence -> 2), Map(score -> 1.0324447202802176, sentence -> 0), Map(score -> 0.882669009555137, sentence -> 0))</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>The Star News covers Taylor County with publications such as: The Star News, The Star News Shopper. I create visual solutions for clients using a mix of creative skills and commercial awareness while having a good attitude and an open mind for constructive criticism.</td><td>List(star news, taylor county, star news, star news, news shopper, star news covers, star news shopper)</td><td>List(Map(score -> 0.08632855968821534, sentence -> 0), Map(score -> 0.3000139986750364, sentence -> 0), Map(score -> 0.08632855968821534, sentence -> 0), Map(score -> 0.08632855968821534, sentence -> 0), Map(score -> 0.30094279834533755, sentence -> 0), Map(score -> 0.31378701946054033, sentence -> 0), Map(score -> 0.17793336583739777, sentence -> 0))</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>Volunteer graphic designer on projects to help promote the non-profit solar energy industry.</td><td>List(volunteer graphic, graphic designer, help promote, solar energy, energy industry)</td><td>List(Map(score -> 1.1369811712108198, sentence -> 0), Map(score -> 1.941529781644477, sentence -> 0), Map(score -> 1.2811431701438607, sentence -> 0), Map(score -> 1.2811431701438607, sentence -> 0), Map(score -> 1.2811431701438607, sentence -> 0))</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>TP Printing covers Clark, Western Marathon and Taylor Counties with publications such as: The Tribune-Phonograph, The Record-Review, Central Wisconsin Shopper and Tribune Record Gleaner. I was responsible for creating visual solutions for clients using a mix of creative skills and commercial awa</td><td>List(western marathon, wisconsin shopper, record gleaner, central wisconsin shopper, tribune record gleaner)</td><td>List(Map(score -> 0.2874099033208374, sentence -> 0), Map(score -> 0.2874099033208374, sentence -> 0), Map(score -> 0.2874099033208374, sentence -> 0), Map(score -> 0.19489493646761252, sentence -> 0), Map(score -> 0.19489493646761252, sentence -> 0))</td></tr><tr><td>Administrative support and managed daily operations of the facility, scheduled building use by the Center, its tenants and occasional users, increased social media marketing, managed WordPress website, designed marketing materials and seasonal brochures, managed membership database, created mo</td><td>List(managed daily operations, social media marketing, managed wordpress website, designed marketing materials, managed membership database)</td><td>List(Map(score -> 0.2057268230718544, sentence -> 0), Map(score -> 0.23217868355189197, sentence -> 0), Map(score -> 0.2057268230718544, sentence -> 0), Map(score -> 0.23217868355189197, sentence -> 0), Map(score -> 0.2057268230718544, sentence -> 0))</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>I assist financial advisors & insurance producers to help grow their business by providing a wide array products, underwriting and case design expertise along with point of sale and marketing support.</td><td>List(financial advisors, wide array, array products, case design, design expertise)</td><td>List(Map(score -> 0.6415913950461233, sentence -> 0), Map(score -> 0.6415913950461233, sentence -> 0), Map(score -> 0.6415913950461233, sentence -> 0), Map(score -> 0.6415913950461233, sentence -> 0), Map(score -> 0.6415913950461233, sentence -> 0))</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>I taught all core academic classes to my 4th grade class.</td><td>List(core academic, academic classes, grade class, taught all core, core academic classes)</td><td>List(Map(score -> 1.2811431701438607, sentence -> 0), Map(score -> 1.2811431701438607, sentence -> 0), Map(score -> 1.2811431701438607, sentence -> 0), Map(score -> 4.257302130400798, sentence -> 0), Map(score -> 2.6823892323752503, sentence -> 0))</td></tr><tr><td>I taught all core academic classes to my 4th grade class.</td><td>List(core academic, academic classes, grade class, taught all core, core academic classes)</td><td>List(Map(score -> 1.2811431701438607, sentence -> 0), Map(score -> 1.2811431701438607, sentence -> 0), Map(score -> 1.2811431701438607, sentence -> 0), Map(score -> 4.257302130400798, sentence -> 0), Map(score -> 2.6823892323752503, sentence -> 0))</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>Historic preservation & development to restore our own neighborhood; The historic OTR Brewery District in Cincinnati.</td><td>List(historic otr, otr brewery, brewery district, otr brewery district, district in cincinnati)</td><td>List(Map(score -> 1.1258617987991613, sentence -> 1), Map(score -> 0.47537024564829994, sentence -> 1), Map(score -> 0.47537024564829994, sentence -> 1), Map(score -> 0.45817870305258784, sentence -> 1), Map(score -> 1.3128349410809044, sentence -> 1))</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr><tr><td>null</td><td>List()</td><td>List()</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         null,
         [],
         []
        ],
        [
         null,
         [],
         []
        ],
        [
         null,
         [],
         []
        ],
        [
         null,
         [],
         []
        ],
        [
         "Program and operations manager for all TMA services, primarily focused on EZRide Shuttle (fixed route commuter shuttle linking commuter rail terminal and Cambridge worksites, with 2,000-3,000 daily boardings). Also oversee Emergency Ride Home program and commuter information programs. Manage NextBus AVL system for shuttles.",
         [
          "tma services",
          "cambridge worksites",
          "emergency ride",
          "ride home",
          "emergency ride home"
         ],
         [
          {
           "score": "0.5464460443720845",
           "sentence": "0"
          },
          {
           "score": "0.5464460443720845",
           "sentence": "0"
          },
          {
           "score": "0.43687228818560925",
           "sentence": "1"
          },
          {
           "score": "0.43687228818560925",
           "sentence": "1"
          },
          {
           "score": "0.39617831238884077",
           "sentence": "1"
          }
         ]
        ],
        [
         "Service coordinator for Waltham CitiBus network, as well as other TMA commuter shuttle routes. CitiBus provided fixed-route transit service to parts of Waltham not fully served by the MBTA. Also assisted with management of the Council's other shuttles (Alewife, Needham, and Bentley College).",
         [
          "waltham citibus",
          "tma commuter",
          "bentley college",
          "waltham citibus network",
          "tma commuter shuttle"
         ],
         [
          {
           "score": "0.6057436402052977",
           "sentence": "0"
          },
          {
           "score": "0.5463402994396243",
           "sentence": "0"
          },
          {
           "score": "0.5283089023826478",
           "sentence": "2"
          },
          {
           "score": "1.0324447202802176",
           "sentence": "0"
          },
          {
           "score": "0.882669009555137",
           "sentence": "0"
          }
         ]
        ],
        [
         null,
         [],
         []
        ],
        [
         "The Star News covers Taylor County with publications such as: The Star News, The Star News Shopper. I create visual solutions for clients using a mix of creative skills and commercial awareness while having a good attitude and an open mind for constructive criticism.",
         [
          "star news",
          "taylor county",
          "star news",
          "star news",
          "news shopper",
          "star news covers",
          "star news shopper"
         ],
         [
          {
           "score": "0.08632855968821534",
           "sentence": "0"
          },
          {
           "score": "0.3000139986750364",
           "sentence": "0"
          },
          {
           "score": "0.08632855968821534",
           "sentence": "0"
          },
          {
           "score": "0.08632855968821534",
           "sentence": "0"
          },
          {
           "score": "0.30094279834533755",
           "sentence": "0"
          },
          {
           "score": "0.31378701946054033",
           "sentence": "0"
          },
          {
           "score": "0.17793336583739777",
           "sentence": "0"
          }
         ]
        ],
        [
         null,
         [],
         []
        ],
        [
         "Volunteer graphic designer on projects to help promote the non-profit solar energy industry.",
         [
          "volunteer graphic",
          "graphic designer",
          "help promote",
          "solar energy",
          "energy industry"
         ],
         [
          {
           "score": "1.1369811712108198",
           "sentence": "0"
          },
          {
           "score": "1.941529781644477",
           "sentence": "0"
          },
          {
           "score": "1.2811431701438607",
           "sentence": "0"
          },
          {
           "score": "1.2811431701438607",
           "sentence": "0"
          },
          {
           "score": "1.2811431701438607",
           "sentence": "0"
          }
         ]
        ],
        [
         null,
         [],
         []
        ],
        [
         "TP Printing covers Clark, Western Marathon and Taylor Counties with publications such as: The Tribune-Phonograph, The Record-Review, Central Wisconsin Shopper and Tribune Record Gleaner. I was responsible for creating visual solutions for clients using a mix of creative skills and commercial awa",
         [
          "western marathon",
          "wisconsin shopper",
          "record gleaner",
          "central wisconsin shopper",
          "tribune record gleaner"
         ],
         [
          {
           "score": "0.2874099033208374",
           "sentence": "0"
          },
          {
           "score": "0.2874099033208374",
           "sentence": "0"
          },
          {
           "score": "0.2874099033208374",
           "sentence": "0"
          },
          {
           "score": "0.19489493646761252",
           "sentence": "0"
          },
          {
           "score": "0.19489493646761252",
           "sentence": "0"
          }
         ]
        ],
        [
         "Administrative support and managed daily operations of the facility, scheduled building use by the Center, its tenants and occasional users, increased social media marketing, managed WordPress website, designed marketing materials and seasonal brochures, managed membership database, created mo",
         [
          "managed daily operations",
          "social media marketing",
          "managed wordpress website",
          "designed marketing materials",
          "managed membership database"
         ],
         [
          {
           "score": "0.2057268230718544",
           "sentence": "0"
          },
          {
           "score": "0.23217868355189197",
           "sentence": "0"
          },
          {
           "score": "0.2057268230718544",
           "sentence": "0"
          },
          {
           "score": "0.23217868355189197",
           "sentence": "0"
          },
          {
           "score": "0.2057268230718544",
           "sentence": "0"
          }
         ]
        ],
        [
         null,
         [],
         []
        ],
        [
         null,
         [],
         []
        ],
        [
         null,
         [],
         []
        ],
        [
         null,
         [],
         []
        ],
        [
         null,
         [],
         []
        ],
        [
         null,
         [],
         []
        ],
        [
         null,
         [],
         []
        ],
        [
         "I assist financial advisors & insurance producers to help grow their business by providing a wide array products, underwriting and case design expertise along with point of sale and marketing support.",
         [
          "financial advisors",
          "wide array",
          "array products",
          "case design",
          "design expertise"
         ],
         [
          {
           "score": "0.6415913950461233",
           "sentence": "0"
          },
          {
           "score": "0.6415913950461233",
           "sentence": "0"
          },
          {
           "score": "0.6415913950461233",
           "sentence": "0"
          },
          {
           "score": "0.6415913950461233",
           "sentence": "0"
          },
          {
           "score": "0.6415913950461233",
           "sentence": "0"
          }
         ]
        ],
        [
         null,
         [],
         []
        ],
        [
         null,
         [],
         []
        ],
        [
         "I taught all core academic classes to my 4th grade class.",
         [
          "core academic",
          "academic classes",
          "grade class",
          "taught all core",
          "core academic classes"
         ],
         [
          {
           "score": "1.2811431701438607",
           "sentence": "0"
          },
          {
           "score": "1.2811431701438607",
           "sentence": "0"
          },
          {
           "score": "1.2811431701438607",
           "sentence": "0"
          },
          {
           "score": "4.257302130400798",
           "sentence": "0"
          },
          {
           "score": "2.6823892323752503",
           "sentence": "0"
          }
         ]
        ],
        [
         "I taught all core academic classes to my 4th grade class.",
         [
          "core academic",
          "academic classes",
          "grade class",
          "taught all core",
          "core academic classes"
         ],
         [
          {
           "score": "1.2811431701438607",
           "sentence": "0"
          },
          {
           "score": "1.2811431701438607",
           "sentence": "0"
          },
          {
           "score": "1.2811431701438607",
           "sentence": "0"
          },
          {
           "score": "4.257302130400798",
           "sentence": "0"
          },
          {
           "score": "2.6823892323752503",
           "sentence": "0"
          }
         ]
        ],
        [
         null,
         [],
         []
        ],
        [
         "Historic preservation & development to restore our own neighborhood; The historic OTR Brewery District in Cincinnati.",
         [
          "historic otr",
          "otr brewery",
          "brewery district",
          "otr brewery district",
          "district in cincinnati"
         ],
         [
          {
           "score": "1.1258617987991613",
           "sentence": "1"
          },
          {
           "score": "0.47537024564829994",
           "sentence": "1"
          },
          {
           "score": "0.47537024564829994",
           "sentence": "1"
          },
          {
           "score": "0.45817870305258784",
           "sentence": "1"
          },
          {
           "score": "1.3128349410809044",
           "sentence": "1"
          }
         ]
        ],
        [
         null,
         [],
         []
        ],
        [
         null,
         [],
         []
        ],
        [
         null,
         [],
         []
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "description",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "description_keywords",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "metadata",
         "type": "{\"type\":\"array\",\"elementType\":{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true},\"containsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "key_prof = df_llm.withColumnRenamed(\"description\",\"text\")\n",
    "\n",
    "# Import the required modules and classes\n",
    "from sparknlp.base import DocumentAssembler, Pipeline\n",
    "from sparknlp.annotator import (\n",
    "    SentenceDetector,\n",
    "    Tokenizer,\n",
    "    YakeKeywordExtraction\n",
    ")\n",
    "\n",
    "\n",
    "# Step 1: Transforms raw texts to `document` annotation\n",
    "document = DocumentAssembler() \\\n",
    "            .setInputCol(\"text\") \\\n",
    "            .setOutputCol(\"document\")\n",
    "# Step 2: Sentence Detection\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "            .setInputCols(\"document\") \\\n",
    "            .setOutputCol(\"sentence\")\n",
    "# Step 3: Tokenization\n",
    "token = Tokenizer() \\\n",
    "            .setInputCols(\"sentence\") \\\n",
    "            .setOutputCol(\"token\") \\\n",
    "            .setContextChars([\"(\", \")\", \"?\", \"!\", \".\", \",\"])\n",
    "# Step 4: Keyword Extraction\n",
    "keywords = YakeKeywordExtraction() \\\n",
    "            .setInputCols(\"token\") \\\n",
    "            .setOutputCol(\"keywords\") \\\n",
    "            .setWindowSize(10) \\\n",
    "            .setNKeywords(5)\n",
    "            \n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(stages=[document, sentenceDetector, token, keywords])\n",
    "\n",
    "# Apply the pipeline on 'profiles' DataFrame\n",
    "profiles_with_keywords = pipeline.fit(key_prof).transform(key_prof)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "profiles_with_keywords = profiles_with_keywords.select(col(\"text\").alias(\"description\"), col(\"keywords.result\").alias(\"description_keywords\"), \"keywords.metadata\")\n",
    "\n",
    "profiles_with_keywords.limit(30).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49f5605f-dcc9-4e9f-b9f4-71df73302e9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n|        avg(score)|\n+------------------+\n|0.6076924729907589|\n+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "yake_score_df = profiles_with_keywords.select(\"metadata\")\n",
    "yake_score_df = yake_score_df.filter(size(\"metadata\") > 0)\n",
    "exploded_df_yake = yake_score_df.select(explode(\"metadata\").alias(\"score_dict\"))\n",
    "\n",
    "# Select the \"score\" value from the exploded column\n",
    "score_df_yake = exploded_df_yake.select(\"score_dict.score\")\n",
    "\n",
    "# Calculate the mean of the \"score\" values\n",
    "mean_score_df_yake = score_df_yake.agg(expr(\"avg(score)\"))\n",
    "\n",
    "# Show the resulting mean score\n",
    "mean_score_df_yake.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c7add37-8ef0-4fef-ae8d-42b361908005",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 7. Gemeni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7c5d149-b5f4-4604-972d-3b2f66f14f52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85872725-aef3-48d8-badb-c99886e1753d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>meta_industry</th><th>about</th><th>descriptions</th><th>generated_description</th></tr></thead><tbody><tr><td>\"Doctor\" Phil Bernstein</td><td>Media and Entertainment</td><td>WHAT I DO: I help small and medium-sized Pacific Northwest businesses connect with their target customers, deliver their message, and generate more sales. I do it with broadcast radio advertising and precisely-targeted digital campaigns. WHY IT WORKS: Because Im able to offer a customized advertising plan (leveraging radio and the most effective digital platforms) I can tailor the best methods to reach YOUR specific audience where they are. Based on your target audiences demographics, we'll craft a personalized, custom plan to maximize your reach and impact. We'll choose specific channels and outlets (broadcast or digital) where your potential customers are listening, reading and surfing. Then we'll use my copywriting skills to craft a persuasive message that compels your target to take action. WHO I HELP:  Auto dealerships  Financial services firms  Funeral homes  Furniture stores  Home remodelers  Insurance agencies and brokers  Medical practices  Mortgage companies  Law firms  Dental practices  Retail stores  Plumbers  Senior living communities  Any business that needs to find more customers and make more sales Ready to talk? Call me at 503-323-6611, or email me at philbernstein@iheartmedia.com.</td><td>List(As The Sales \"Doctor\" I write a column on sales and marketing issues for The Paint Contractor, a monthly magazine dedicated to the professional painter., WHAT I DO: I help television station sales departments increase their direct revenue, and teach television Account Executives a system for conducting a thorough and powerful needs analysis, revealing the clients true advertising budget, building a proposal that earns a big piece of that budget, presenting the proposal, closing the businesses, and making it stick. COMPANIES IVE WORKED WITH:  Cordillera Communications  Cox Media Group  Gray Television  Hearst Television  Heartland Media  Paxton Media Group  Raycom Media  Sarkes Tarzian, Inc  Sinclair Broadcast Group  TEGNA  Tribune Media WHY IT WORKS: Each year, Jim Doyle & Associates consultants meet with hundreds of local advertisers in markets big and small, all over the United States. We accompany the Account Executives on sales call, teaching them by example how to build rapport with advertisers, gather the information they need, build and present a powerful television and digital marketing prop, Sold advertising and marketing solutions using the radio, online, and other digital tools of seven local radio stations. The process began with cold calling and proceeded through needs analysis, presentation, closing, and follow-up. As my career continued, I recognized a desperate need in the business community for good, professional , Sold program advertising, fence signs, radio time, season tickets, group sales, and promotional package for the the Beavers, a AAA club then in the Philadelphia Phillies organization. Managed souvenir program and novelty sales, hiring and supervising employees, ordering and tracking inventory, and collecting and depositing revenues. Spoke to community groups, service clubs, and schools to develop better public awareness of Portland Beaver baseball and to generate sales.)</td><td>As an accomplished sales strategist and marketing expert in the media and entertainment industry, I possess a proven track record of helping television stations maximize their direct revenue streams. Through my column in The Paint Contractor, I share my insights on sales and marketing best practices. Drawing upon my extensive experience with renowned organizations including Cordillera Communications and Hearst Television, I empower Account Executives with comprehensive sales techniques. My expertise encompasses in-depth needs analysis, compelling proposal development, persuasive presentations, and effective sales closing strategies. I have successfully implemented these techniques with hundreds of local advertisers across the nation, leveraging my deep understanding of the market and the ability to build strong relationships. My core competencies include:\n",
       "\n",
       "- Sales and Marketing Strategy Development\n",
       "- Television and Digital Advertising Solutions\n",
       "- NEEDS Analysis and Value Proposition Creation\n",
       "- Proposal Writing and Client Acquisition\n",
       "- Presentation and Negotiation Skills\n",
       "- Client Relationship Management and Retention</td></tr><tr><td>A Mohamed Faizal Shariff</td><td>Services</td><td>A Mohamed Faizal Shariff, an IT professional with 9+ years of work experience in the field of Software development using Salesforce platform, Siebel, Oracle CRM-OnDemand application. Expert Software Developer with over 7+ End to End Salesforce CRM Implementations (Cross product & Industry Verticals) for customers across diverse geographies in the areas of:  CRM Consulting, Innovation & Solution Design (Sales / Service & Support)  Integrating Salesforce with third party interfaces using REST API Expert Software Developer dedicated to constantly improving tools and infrastructure to maximize productivity, minimize system downtime and quickly respond to the changing needs of the business. Developed superior design and debugging capabilities, innovative problem-solving skills, and dedication to quality. Proficient in delivering value-based consulting services (Process, Strategy and Product), designing Innovative solution and new Product/App, establishing governance, architecture and delivery standards for customers. Expert in Business process Design & Re-engineering, Customer & User Experience Management, Solution Design & Architecture, Business analysis. Experienced in defining Solution, Application/System, Information, Security, Integration and Technical Architectures. Extensive hands-on experience in Apex, Visualforce, JavaScript, jQuery, Financial Force (PSA), Force.com migration tools (Force.Com IDE, Data loader and Change Sets). Possess hands-on experience in developing lightning applications using Lightning Web components.</td><td>List( Worked alongside the executive team to define quarterly and yearly goals for my pod. Determined the timelines for upcoming projects based on the LOEs from Dev and QA  Involved in application development lifecycle activities that include Analysis, Research, Design, Development and Unit Testing.  Provided Data Migration Strategy document and POC of Shield (Encrypted Data Migration).  Exclusively worked on Migrating 8 years of legacy data which includes attachments.  Created various Reports (summary reports, matrix reports, dashboards, pie charts, and graphics) and folders to assist managers to properly utilize Salesforce as a sales too, A Mohamed Faizal Shariff, an IT professional with 7+ years of work experience in the field of Software development using Salesforce platform, Siebel, Oracle CRM-OnDemand application. Expert Software Developer withover 4+ End to End Salesforce CRM Implementations (Cross product & Industry Verticals) for customers across diverse geographies in the areas of:  CRM Consulting, Innovation & Solution Design (Sales / Service & Support)  Integrating Salesforcewith third party interfaces using REST API Expert Software Developer dedicated to constantly improving tools and infrastructure to maximize productivity, minimize system downtime and quickly respond to the changing needs of the business. Developed superior design and debugging capabilities, innovative problem solving skills and dedication to quality. Proficient in delivering value based consulting services (Process, Strategy and Product), designing Innovative solution and new Product/App, establishing governance, architec,  Worked under SAFe Agile methodology and Waterfall Methodology.  Having experience on Financial Force PSA application.  Experienced all phases of Salesforce Software Development Life Cycle (SDLC) and project life cycle processes from analysis, design, development, testing, imple,  Working as Senior Software Engineer in Infosys, Chennai.  Installation and configuration of Salesforce Environments.  Responsible for creating Fields, Objects, Tabs, Page Layouts, Field Level Security, Dependent Pick lists, Record Types, Relationships, Assignment Rules and Custom Setting)</td><td>Mohamed Faizal Shariff brings over 7 years of comprehensive experience in the Services industry, leveraging his expertise in Software Development and Salesforce platform. Throughout his career, he has consistently exceeded expectations in various roles, including providing valuable consulting services, designing innovative solutions, and optimizing operational processes. His proven ability to define strategic goals, map out project timelines, and deliver successful implementations make him a highly sought-after professional in the Services domain. Furthermore, his contributions to Data Migration, including the development of a Data Migration Strategy document and Proof of Concept of Shield, demonstrate his deep understanding of data management and security best practices. His proficiency in integrating Salesforce with third-party interfaces, adhering to Agile and Waterfall methodologies, and leveraging Financial Force PSA application further solidifies his versatility and expertise within the Services industry.</td></tr><tr><td>A-aron Peters</td><td>Technology</td><td>\"A-aron\" Peters (usually signed All my best ~AMP) Highly detailed, process driven, internally motivated extrovert. I meet strangers for about 3 seconds, but my closest friends (and wife) still consider me enigmatic, despite years of working to be transparent. Often referred to as 123, the tiniest minutiae stands out, and there is an overwhelming drive to make it fit, or correct. People are my drive. Ever since I was small, I have wanted to make an impact on peoples lives. At one point I told my mother I wanted to be a bartender (THAT was not acceptable in our Baptist household!!). Empathy and sympathy are not words typically associated with my personality. There is a firm belief that if you want something better, you (and only you) have the power to make it better, you just have to find the will. Thinkers are my heroes. Rudyard Kipling wrote a poem If and outside of the Bible, that has GOT to be the best piece of prose ever put to paper ( See below) If you can keep your head when all about you Are losing theirs and blaming it on you; If you can trust yourself when all men doubt you, But make allowance for their doubting too: If you can wait and not be tired by waiting, Or, being lied about, don't deal in lies, Or being hated don't give way to hating, And yet don't look too good, nor talk too wise; If you can dream - and not make dreams your master; If you can think - and not make thoughts your aim, If you can meet with Triumph and Disaster And treat those two impostors just the same:. If you can bear to hear the truth you've spoken Twisted by knaves to make a trap for fools, Or watch the things you gave your life to, broken, And stoop and build'em up with worn-out tools; If you can make one heap of all your winnings And risk it on one turn of pitch-and-toss, And lose, and start again at your beginnings, And never breathe a word about your loss: If you can force your heart and nerve and sinew To serve your turn long after they are gone, And so hold on when there is nothing in you Except the Will which says to them: \"Hold on!\" If you can talk with crowds and keep your virtue, Or walk with Kings - nor lose the common touch, If neither foes nor loving friends can hurt you, If all men count with you, but none too much: If you can fill the unforgiving minute With sixty seconds' worth of distance run, Yours is the Earth and everything that's in it, And - which is more - you'll be a Man, my son! Convenience is the author of complacency, but decision is the enabler of intention All my best ~AMP</td><td>List(Providing solutions to reduce stress and add value for our business partners.)</td><td>With a background in technology, I excel at leveraging my expertise to provide innovative solutions that enhance efficiency and streamline processes. My past experience in developing and implementing technological frameworks, data analysis, and project management has honed my ability to identify areas of improvement and create tailored solutions. I am adept at understanding business needs and translating them into actionable technical plans. My drive to reduce stress and add value for stakeholders has consistently driven me to seek out opportunities to automate tasks, optimize workflows, and enhance collaboration. I am eager to contribute my skills and experience to a dynamic organization where I can make a meaningful impact through technology.</td></tr><tr><td>AJ (Aaron) Brody</td><td>Technology</td><td>Started waiting on tables, progressed to AT&T long distance sales, into finessing print and internet ad sales, to lastly membership sales. I have ample experience in selling anything to everyone. I also had the opportunity to try my hand as a writer/columnist. I have been published in newspaper, magazine as well as on the internet.My experience in phone sales brought me to creating and running two Business Development Departments with in the LA Car Guy Auto Group. Successfully ran a team of up to six where we would use excellent customer service skills coupled with our product knowledge to pre-sell and schedule a sales appointment. I am currently Business Development Director at Toyota Santa Monica, where I revived the department to smash all expected goals and help the dealership out gross month to month. My creative edge mixed with my practical and empirical learning has crafted my ability to succeed in all that I do. He who loses his dreams, loses his soul along with it.</td><td>List(Director of business development and Auto Alert Team, Matchmaking for the discerning professional in Southern California. Providing discrete, and personalized matchmaking for the upscale SoCal community., As an account executive for Outlook, I introduce the niche gay and lesbian market to businesses looking to advertise.)</td><td>With a proven track record in business development and matchmaking, I am eager to contribute my expertise to the technology industry. As Director of Business Development for Auto Alert Team, I successfully expanded our reach, connecting discerning professionals with tailored solutions. Prior to that, as an Account Executive for Outlook, I effectively introduced the niche gay and lesbian market to businesses, leveraging my understanding of target demographics. My strong communication skills, relationship-building abilities, and passion for technology make me an ideal candidate to drive growth and innovation in your organization. I am confident that my strategic thinking, market analysis capabilities, and ability to forge lasting partnerships will enable me to excel in this role and contribute to your company's success.</td></tr><tr><td>AJ Ferrara</td><td>Government and Public Policy</td><td>Experienced formal and informal educator with a demonstrated history of working in the civic & social organization industry. Skilled in Environmental Awareness, Environmental Education, Teamwork, and Data Analysis, with additional background in field geology and paleontology collections. Strong administrative professional with a Bachelor of Science (BS) focused in Geological and Environmental Sciences.</td><td>List(At one of the Park Service's busiest Visitor Education Centers I led tours, gave short and long form interpretive programs on topics ranging from ecology to history to geology, and roved geyser basins to make contact with Yellowstone visitors. In peak season the Old Faithful Visitor Education Center receives upwards of 15,000 visitors per day. As a result opportunities for informal interpretation abound, as do situations that, As a Program Assistant at the Los Angeles Zoo my job, first and foremost, is ensuring that formal interpretive programs run smoothly. To those ends I delivered and assisted in delivery of formal and informal educational events. I regularly prepare classrooms and accommodations for out guests, including sett, As Senior Curatorial Technician I worked as part of a team to ensure our paleontological collections were maintained for easy future access and study. Primarily we worked to catalogue, organize, and protect a warehouse of fossils, mostly found during excavation for construction projects around Orange County, dating back to the 1, During my time at the Palos Verdes Peninsula Land Conservancy I completed a range of assignments, from assisting in habitat restoration projects, to designing and updating exhibits, to leading tour groups. Indoors and out I acted as a point of contact for the public who used the spaces were preserved, discussing the work we were doing, the value of natural spaces, and the virtues of our local plants and animals., Taught two periods of a Cartooning class. Additionally acted as a camp counselor helping to organize events, working backstage at the camp's musical show, and putting on an art show to showcase the class's work. Worked with children age nine to fourteen.)</td><td>Through my diverse roles in public engagement, education, and conservation, I have fostered a deep understanding of environmental and historical interpretation, public policy, and stakeholder relations. In the dynamic environment of Yellowstone National Park, I excelled as a lead interpreter, crafting engaging programs on diverse topics for audiences of all ages and backgrounds. As a Program Assistant at the Los Angeles Zoo, I coordinated educational events, ensuring their smooth execution. My experience at the Palos Verdes Peninsula Land Conservancy equipped me to navigate the intersection of natural resource management and community outreach. I have also contributed to the field of paleontology as a Senior Curatorial Technician, maintaining invaluable fossil collections for future research and public access. These experiences have honed my skills in communication, collaboration, and environmental stewardship, enabling me to make a meaningful impact in the realm of Government and Public Policy.</td></tr><tr><td>ALEJANDRO MUOZ G. FundacinInternacionalParaElReencuentro</td><td>Media and Entertainment</td><td>The Colombian journalist ALEJANDRO MUOZ GARZON, creator of the FOUNDATION INTERNATIONAL FOR THE REUNION, www.funreencuentros.com/ pioneered national television to start with conducting historical research encounters, some of which were and are issued by national channels and Rafael Poveda foreign and TV, Caracol TV, Tevecine, JES Productions, Univision and Telemundo. Equally unique is the pioneer and promoter of desaprecidos search activities in media and packaging of consumer products, including milk cartons \"ALPINA\", campaign between 2001 and 2005 in Colombia; period during which about Colombian one hundred patients disappeared, they returned to their homes with the publication of photographs in dairy packaging. El periodista Colombiano ALEJANDRO MUOZ GARZON, gestor de la FUNDACION INTERNACIONAL PARA EL REENCUENTRO, www.funreencuentros.com/ es pionero en la televisin nacional al iniciar con sus investigaciones la realizacin de histricos reencuentros, algunos de los cuales fueron y son emitidos por canales nacionales y extranjeros como Rafael Poveda Televisin, Caracol TV, Tevecine, Producciones JES, Univisin y Telemundo. Igualmente es pionero y nico impulsador de actividades de bsqueda de desaprecidos en medios de comunicacin y empaques de productos de consumo masivo, entre ellos en las cajas de leche ALPINA, campaa realizada entre los aos 2001 y 2005 en Colombia; periodo durante el cual, cerca de un centenar de Colombianos enfermos desaparecidos, regresaron a sus hogares gracias a la publicacin de fotografias en los empaques lacteos.</td><td>List(Investigo el paradero de Padres, Madres, Hermanos e Hijos de origen latinoamericano que se han desaparecido por muchos aos y por razones de violencia intrafamiliar o adopcin y una vez ubicados y asistidos sicoafectiva y mdicamente tras la aceptacin y comprobacion cientfica (Test ADN s es necesario) procedemos a ayudarlos en el logro del abrazo tan esperado, As benefactor and volunteer for the Foundation for the Reunion, www.funreencuentros.com/ I have witnessed for more than twelve years the outstanding work of this Foundation located in Bogota, Colombia. This institution was created to reacquaint healthy and successfully adopted Colombian individuals with their biological families, through a process of psycho-emotional adjustment accompanied by professionals in the field of documentary research, tracking, location and preparation for the reunion. During this time, while gaining experience on the issue of family separation and reunion, this institution that I highly recommend has performed an average of 10,669 reunions of Colombians lost from their families. Among them, 3,599 reunions have been made for Colombian adopted who sought, REPORTERO Y PRESENTADOR DE NOTAS PERIODISTICAS CON TINTE HUMORISTICO COMPROBANDO TEMAS Y REFRANES POPULARES COMO: \"DE TAL PALO TAL ASTILLA\" \"MATRIMONIO Y MORTAJA DEL CIELO BAJA\" \"LAS COSAS SE PARECEN A SUS DUENOS\" ETC. EN SABADOS FELICES SECCION LAS AVENTURAS DEL MACHORR)</td><td>For over a decade, my passion for bridging familial connections has driven me as a volunteer at the Foundation for the Reunion, where I've witnessed the transformative power of reuniting long-lost loved ones. My experience in uncovering their whereabouts and facilitating their psychoemotional recovery has honed my skills in documentary research, tracking, and location. Through the lens of popular sayings, I've explored the human condition as a reporter and presenter for Sbado Felices, delving into the themes of family bonds, destiny, and personal growth. These experiences have instilled in me a deep understanding of the emotional complexities and the profound impact of reconnecting families. I am eager to translate these skills into the dynamic realm of Media and Entertainment, where I can utilize my storytelling abilities and research acumen to engage and inspire audiences through compelling narratives that celebrate the resilience of the human spirit and the indomitable power of family connections.</td></tr><tr><td>ALLISON CHUNG</td><td>Education and Training</td><td>Experienced Accounts Payable Specialist with a demonstrated history of working in the primary/secondary education industry. Skilled in Nonprofit Organizations, Microsoft Word, Team Building, Fundraising, and Leadership. Strong operations professional with a Masters degree (M.S) focused in Human Service Counseling: Marriage and Family from Liberty University.</td><td>List(Performs difficult clerical tasks involving the application of bookkeeping principles and account keeping practices in order to maintain the financial accounts and records. Prepares and inputs accounting data into the Oracle financial system. Reviews invoice, Responsible for all aspects of the accounts payable process.Tracked the budget on a weekly basis during the accounts payable process. Responsible for reconciliation of all credit card payments. Reviewed and processed all expense reports for the company. Prepared billing invoices. Updated employee records. Responsible for new hire orientation. Responsible for all aspects of 1099 preparation. Assisted in payroll processes. Assisted in other fiscal and human resource duties as assigned., Prepared and entered all lockbox payments into the automated accounting system.Posted payment batches to the correct accounting period and prepared, filed and distributed final reports. Reviewed and processed expense reports and refund requests for appropriate authorizations and assigned the correct accounting entry.Prepared and entered journal entri)</td><td>I am a highly skilled and experienced professional with a proven track record in Education and Training. Throughout my career, I have consistently exceeded expectations in various roles within the industry, leveraging my expertise in financial management, accounting principles, and human resource administration. As a former accounts payable specialist responsible for all aspects of the process, I meticulously tracked budgets, reconciled credit card payments, and processed expense reports. My ability to maintain accurate financial records and ensure compliance with industry standards is a testament to my unwavering attention to detail. Furthermore, I have extensive experience in payroll processing, new hire orientation, and 1099 preparation, demonstrating my comprehensive understanding of human resource functions. My versatility and adaptability have enabled me to provide support in both fiscal and human resource capacities, showcasing my commitment to efficiency and teamwork. I am confident that I can bring my knowledge and skills to your Education and Training organization and make a significant contribution to its success.</td></tr><tr><td>ASHLEA HERRING</td><td>Retail and Consumer Goods</td><td>I am an outgoing fun people loving person.</td><td>List(Calling the Client, picking up the client taking the client to their destination, cleaning the limo or party bus and pre trip and post trip)</td><td>Throughout my tenure in the retail and consumer goods industry, I have consistently exceeded expectations in providing exceptional customer service and maintaining the highest standards of excellence. As a Limo/Party Bus Driver, I excelled in ensuring the safety, comfort, and satisfaction of clients. I proactively called clients, punctually picked them up, and safely transported them to their destinations. Maintaining a pristine appearance of the vehicles was paramount, as I meticulously cleaned and inspected both limos and party buses before and after each trip. My keen attention to detail and commitment to providing a seamless experience have earned me a reputation for reliability and professionalism. I am confident that my skills and experience would make me a valuable asset to any organization seeking a dedicated and customer-focused individual in the retail and consumer goods sector.</td></tr><tr><td>Aaron Acuna</td><td>Government and Public Policy</td><td>Have worked State/Government jobs since 2018. Good with data entry in Excel and copy writing/editing in Word. Have extensively used Teams and Outlook but am proficient in Google systems as well (Calendars, Sheets, etc.). From 2016-2018 I worked as a student employee for the University of Alaska, Anchorage (UAA) in various jobs, including as (1) a Library Intern (designing posters, working the front desk), (2) an English Department Intern (writing the website's scholarships page), (3) an Information Desk Clerk for the Learning Center, and (4) an English Tutor (proofreading/editing student papers, running the ESL Conversation Group). I was the unofficial records custodian for Alaska Occupational Safety & Health (AKOSH, or Alaska OSHA) from 2018-2020 in which I handled confidential records requests and requests for information under the Alaska Public Records Act (APRA). At that time, I took an Excel 101 course as voluntary job training. From 2020-2022 I spent most of my job at the State Ombudsman's Office copy-writing nuanced letters going out to various types of clients, including confidential responses to citizens and other state agencies. Since 2022 I've been working with the State of Alaska's FEMA Team in the Department of Health, in which I track and enter budget data in extensive Excel spreadsheets</td><td>List(FEMA Team data reviewer - Remote date entry, file organization, team meetings)</td><td>With a proven track record as a FEMA Team Data Reviewer, I bring a comprehensive skillset to government and public policy roles. My expertise in remote data entry, file organization, and team collaboration has honed my ability to handle sensitive information and contribute to high-priority initiatives. I am adept at extracting critical data, maintaining meticulous records, and ensuring efficient workflow. Moreover, my participation in team meetings has strengthened my communication and coordination abilities, enabling me to work effectively in a diverse and results-oriented environment. I am confident that my experience and commitment to accuracy, confidentiality, and public service will make me a valuable asset to any organization seeking to advance its mission in the government and public policy sector.</td></tr><tr><td>Aaron Baltz</td><td>Manufacturing</td><td>Pursuing a career in non-destructive testing and aerospace inspection.</td><td>List(Electro-Mechanical Inspection, Tear down, evaluate and repair aircraft heavy engine nacelles and reversers.)</td><td>Seeking a Manufacturing role where I can leverage my expertise in Electro-Mechanical Inspection, gained through meticulously evaluating and repairing aircraft heavy engine nacelles and reversers. My proficiency in troubleshooting and repairing complex mechanical systems translates seamlessly to the manufacturing environment, enabling me to identify and resolve production-related issues promptly and effectively. With a keen eye for detail, I possess the ability to assess equipment functionality, diagnose faults, and implement corrective actions, ensuring optimal operational efficiency and minimizing downtime. Additionally, my familiarity with industry-specific tools and methodologies enables me to work collaboratively with production teams to optimize processes and enhance quality control measures, ultimately contributing to enhanced productivity and cost reduction within the manufacturing sector.</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "\"Doctor\" Phil Bernstein",
         "Media and Entertainment",
         "WHAT I DO: I help small and medium-sized Pacific Northwest businesses connect with their target customers, deliver their message, and generate more sales. I do it with broadcast radio advertising and precisely-targeted digital campaigns. WHY IT WORKS: Because Im able to offer a customized advertising plan (leveraging radio and the most effective digital platforms) I can tailor the best methods to reach YOUR specific audience where they are. Based on your target audiences demographics, we'll craft a personalized, custom plan to maximize your reach and impact. We'll choose specific channels and outlets (broadcast or digital) where your potential customers are listening, reading and surfing. Then we'll use my copywriting skills to craft a persuasive message that compels your target to take action. WHO I HELP:  Auto dealerships  Financial services firms  Funeral homes  Furniture stores  Home remodelers  Insurance agencies and brokers  Medical practices  Mortgage companies  Law firms  Dental practices  Retail stores  Plumbers  Senior living communities  Any business that needs to find more customers and make more sales Ready to talk? Call me at 503-323-6611, or email me at philbernstein@iheartmedia.com.",
         [
          "As The Sales \"Doctor\" I write a column on sales and marketing issues for The Paint Contractor, a monthly magazine dedicated to the professional painter.",
          "WHAT I DO: I help television station sales departments increase their direct revenue, and teach television Account Executives a system for conducting a thorough and powerful needs analysis, revealing the clients true advertising budget, building a proposal that earns a big piece of that budget, presenting the proposal, closing the businesses, and making it stick. COMPANIES IVE WORKED WITH:  Cordillera Communications  Cox Media Group  Gray Television  Hearst Television  Heartland Media  Paxton Media Group  Raycom Media  Sarkes Tarzian, Inc  Sinclair Broadcast Group  TEGNA  Tribune Media WHY IT WORKS: Each year, Jim Doyle & Associates consultants meet with hundreds of local advertisers in markets big and small, all over the United States. We accompany the Account Executives on sales call, teaching them by example how to build rapport with advertisers, gather the information they need, build and present a powerful television and digital marketing prop",
          "Sold advertising and marketing solutions using the radio, online, and other digital tools of seven local radio stations. The process began with cold calling and proceeded through needs analysis, presentation, closing, and follow-up. As my career continued, I recognized a desperate need in the business community for good, professional ",
          "Sold program advertising, fence signs, radio time, season tickets, group sales, and promotional package for the the Beavers, a AAA club then in the Philadelphia Phillies organization. Managed souvenir program and novelty sales, hiring and supervising employees, ordering and tracking inventory, and collecting and depositing revenues. Spoke to community groups, service clubs, and schools to develop better public awareness of Portland Beaver baseball and to generate sales."
         ],
         "As an accomplished sales strategist and marketing expert in the media and entertainment industry, I possess a proven track record of helping television stations maximize their direct revenue streams. Through my column in The Paint Contractor, I share my insights on sales and marketing best practices. Drawing upon my extensive experience with renowned organizations including Cordillera Communications and Hearst Television, I empower Account Executives with comprehensive sales techniques. My expertise encompasses in-depth needs analysis, compelling proposal development, persuasive presentations, and effective sales closing strategies. I have successfully implemented these techniques with hundreds of local advertisers across the nation, leveraging my deep understanding of the market and the ability to build strong relationships. My core competencies include:\n\n- Sales and Marketing Strategy Development\n- Television and Digital Advertising Solutions\n- NEEDS Analysis and Value Proposition Creation\n- Proposal Writing and Client Acquisition\n- Presentation and Negotiation Skills\n- Client Relationship Management and Retention"
        ],
        [
         "A Mohamed Faizal Shariff",
         "Services",
         "A Mohamed Faizal Shariff, an IT professional with 9+ years of work experience in the field of Software development using Salesforce platform, Siebel, Oracle CRM-OnDemand application. Expert Software Developer with over 7+ End to End Salesforce CRM Implementations (Cross product & Industry Verticals) for customers across diverse geographies in the areas of:  CRM Consulting, Innovation & Solution Design (Sales / Service & Support)  Integrating Salesforce with third party interfaces using REST API Expert Software Developer dedicated to constantly improving tools and infrastructure to maximize productivity, minimize system downtime and quickly respond to the changing needs of the business. Developed superior design and debugging capabilities, innovative problem-solving skills, and dedication to quality. Proficient in delivering value-based consulting services (Process, Strategy and Product), designing Innovative solution and new Product/App, establishing governance, architecture and delivery standards for customers. Expert in Business process Design & Re-engineering, Customer & User Experience Management, Solution Design & Architecture, Business analysis. Experienced in defining Solution, Application/System, Information, Security, Integration and Technical Architectures. Extensive hands-on experience in Apex, Visualforce, JavaScript, jQuery, Financial Force (PSA), Force.com migration tools (Force.Com IDE, Data loader and Change Sets). Possess hands-on experience in developing lightning applications using Lightning Web components.",
         [
          " Worked alongside the executive team to define quarterly and yearly goals for my pod. Determined the timelines for upcoming projects based on the LOEs from Dev and QA  Involved in application development lifecycle activities that include Analysis, Research, Design, Development and Unit Testing.  Provided Data Migration Strategy document and POC of Shield (Encrypted Data Migration).  Exclusively worked on Migrating 8 years of legacy data which includes attachments.  Created various Reports (summary reports, matrix reports, dashboards, pie charts, and graphics) and folders to assist managers to properly utilize Salesforce as a sales too",
          "A Mohamed Faizal Shariff, an IT professional with 7+ years of work experience in the field of Software development using Salesforce platform, Siebel, Oracle CRM-OnDemand application. Expert Software Developer withover 4+ End to End Salesforce CRM Implementations (Cross product & Industry Verticals) for customers across diverse geographies in the areas of:  CRM Consulting, Innovation & Solution Design (Sales / Service & Support)  Integrating Salesforcewith third party interfaces using REST API Expert Software Developer dedicated to constantly improving tools and infrastructure to maximize productivity, minimize system downtime and quickly respond to the changing needs of the business. Developed superior design and debugging capabilities, innovative problem solving skills and dedication to quality. Proficient in delivering value based consulting services (Process, Strategy and Product), designing Innovative solution and new Product/App, establishing governance, architec",
          " Worked under SAFe Agile methodology and Waterfall Methodology.  Having experience on Financial Force PSA application.  Experienced all phases of Salesforce Software Development Life Cycle (SDLC) and project life cycle processes from analysis, design, development, testing, imple",
          " Working as Senior Software Engineer in Infosys, Chennai.  Installation and configuration of Salesforce Environments.  Responsible for creating Fields, Objects, Tabs, Page Layouts, Field Level Security, Dependent Pick lists, Record Types, Relationships, Assignment Rules and Custom Setting"
         ],
         "Mohamed Faizal Shariff brings over 7 years of comprehensive experience in the Services industry, leveraging his expertise in Software Development and Salesforce platform. Throughout his career, he has consistently exceeded expectations in various roles, including providing valuable consulting services, designing innovative solutions, and optimizing operational processes. His proven ability to define strategic goals, map out project timelines, and deliver successful implementations make him a highly sought-after professional in the Services domain. Furthermore, his contributions to Data Migration, including the development of a Data Migration Strategy document and Proof of Concept of Shield, demonstrate his deep understanding of data management and security best practices. His proficiency in integrating Salesforce with third-party interfaces, adhering to Agile and Waterfall methodologies, and leveraging Financial Force PSA application further solidifies his versatility and expertise within the Services industry."
        ],
        [
         "A-aron Peters",
         "Technology",
         "\"A-aron\" Peters (usually signed All my best ~AMP) Highly detailed, process driven, internally motivated extrovert. I meet strangers for about 3 seconds, but my closest friends (and wife) still consider me enigmatic, despite years of working to be transparent. Often referred to as 123, the tiniest minutiae stands out, and there is an overwhelming drive to make it fit, or correct. People are my drive. Ever since I was small, I have wanted to make an impact on peoples lives. At one point I told my mother I wanted to be a bartender (THAT was not acceptable in our Baptist household!!). Empathy and sympathy are not words typically associated with my personality. There is a firm belief that if you want something better, you (and only you) have the power to make it better, you just have to find the will. Thinkers are my heroes. Rudyard Kipling wrote a poem If and outside of the Bible, that has GOT to be the best piece of prose ever put to paper ( See below) If you can keep your head when all about you Are losing theirs and blaming it on you; If you can trust yourself when all men doubt you, But make allowance for their doubting too: If you can wait and not be tired by waiting, Or, being lied about, don't deal in lies, Or being hated don't give way to hating, And yet don't look too good, nor talk too wise; If you can dream - and not make dreams your master; If you can think - and not make thoughts your aim, If you can meet with Triumph and Disaster And treat those two impostors just the same:. If you can bear to hear the truth you've spoken Twisted by knaves to make a trap for fools, Or watch the things you gave your life to, broken, And stoop and build'em up with worn-out tools; If you can make one heap of all your winnings And risk it on one turn of pitch-and-toss, And lose, and start again at your beginnings, And never breathe a word about your loss: If you can force your heart and nerve and sinew To serve your turn long after they are gone, And so hold on when there is nothing in you Except the Will which says to them: \"Hold on!\" If you can talk with crowds and keep your virtue, Or walk with Kings - nor lose the common touch, If neither foes nor loving friends can hurt you, If all men count with you, but none too much: If you can fill the unforgiving minute With sixty seconds' worth of distance run, Yours is the Earth and everything that's in it, And - which is more - you'll be a Man, my son! Convenience is the author of complacency, but decision is the enabler of intention All my best ~AMP",
         [
          "Providing solutions to reduce stress and add value for our business partners."
         ],
         "With a background in technology, I excel at leveraging my expertise to provide innovative solutions that enhance efficiency and streamline processes. My past experience in developing and implementing technological frameworks, data analysis, and project management has honed my ability to identify areas of improvement and create tailored solutions. I am adept at understanding business needs and translating them into actionable technical plans. My drive to reduce stress and add value for stakeholders has consistently driven me to seek out opportunities to automate tasks, optimize workflows, and enhance collaboration. I am eager to contribute my skills and experience to a dynamic organization where I can make a meaningful impact through technology."
        ],
        [
         "AJ (Aaron) Brody",
         "Technology",
         "Started waiting on tables, progressed to AT&T long distance sales, into finessing print and internet ad sales, to lastly membership sales. I have ample experience in selling anything to everyone. I also had the opportunity to try my hand as a writer/columnist. I have been published in newspaper, magazine as well as on the internet.My experience in phone sales brought me to creating and running two Business Development Departments with in the LA Car Guy Auto Group. Successfully ran a team of up to six where we would use excellent customer service skills coupled with our product knowledge to pre-sell and schedule a sales appointment. I am currently Business Development Director at Toyota Santa Monica, where I revived the department to smash all expected goals and help the dealership out gross month to month. My creative edge mixed with my practical and empirical learning has crafted my ability to succeed in all that I do. He who loses his dreams, loses his soul along with it.",
         [
          "Director of business development and Auto Alert Team",
          "Matchmaking for the discerning professional in Southern California. Providing discrete, and personalized matchmaking for the upscale SoCal community.",
          "As an account executive for Outlook, I introduce the niche gay and lesbian market to businesses looking to advertise."
         ],
         "With a proven track record in business development and matchmaking, I am eager to contribute my expertise to the technology industry. As Director of Business Development for Auto Alert Team, I successfully expanded our reach, connecting discerning professionals with tailored solutions. Prior to that, as an Account Executive for Outlook, I effectively introduced the niche gay and lesbian market to businesses, leveraging my understanding of target demographics. My strong communication skills, relationship-building abilities, and passion for technology make me an ideal candidate to drive growth and innovation in your organization. I am confident that my strategic thinking, market analysis capabilities, and ability to forge lasting partnerships will enable me to excel in this role and contribute to your company's success."
        ],
        [
         "AJ Ferrara",
         "Government and Public Policy",
         "Experienced formal and informal educator with a demonstrated history of working in the civic & social organization industry. Skilled in Environmental Awareness, Environmental Education, Teamwork, and Data Analysis, with additional background in field geology and paleontology collections. Strong administrative professional with a Bachelor of Science (BS) focused in Geological and Environmental Sciences.",
         [
          "At one of the Park Service's busiest Visitor Education Centers I led tours, gave short and long form interpretive programs on topics ranging from ecology to history to geology, and roved geyser basins to make contact with Yellowstone visitors. In peak season the Old Faithful Visitor Education Center receives upwards of 15,000 visitors per day. As a result opportunities for informal interpretation abound, as do situations that",
          "As a Program Assistant at the Los Angeles Zoo my job, first and foremost, is ensuring that formal interpretive programs run smoothly. To those ends I delivered and assisted in delivery of formal and informal educational events. I regularly prepare classrooms and accommodations for out guests, including sett",
          "As Senior Curatorial Technician I worked as part of a team to ensure our paleontological collections were maintained for easy future access and study. Primarily we worked to catalogue, organize, and protect a warehouse of fossils, mostly found during excavation for construction projects around Orange County, dating back to the 1",
          "During my time at the Palos Verdes Peninsula Land Conservancy I completed a range of assignments, from assisting in habitat restoration projects, to designing and updating exhibits, to leading tour groups. Indoors and out I acted as a point of contact for the public who used the spaces were preserved, discussing the work we were doing, the value of natural spaces, and the virtues of our local plants and animals.",
          "Taught two periods of a Cartooning class. Additionally acted as a camp counselor helping to organize events, working backstage at the camp's musical show, and putting on an art show to showcase the class's work. Worked with children age nine to fourteen."
         ],
         "Through my diverse roles in public engagement, education, and conservation, I have fostered a deep understanding of environmental and historical interpretation, public policy, and stakeholder relations. In the dynamic environment of Yellowstone National Park, I excelled as a lead interpreter, crafting engaging programs on diverse topics for audiences of all ages and backgrounds. As a Program Assistant at the Los Angeles Zoo, I coordinated educational events, ensuring their smooth execution. My experience at the Palos Verdes Peninsula Land Conservancy equipped me to navigate the intersection of natural resource management and community outreach. I have also contributed to the field of paleontology as a Senior Curatorial Technician, maintaining invaluable fossil collections for future research and public access. These experiences have honed my skills in communication, collaboration, and environmental stewardship, enabling me to make a meaningful impact in the realm of Government and Public Policy."
        ],
        [
         "ALEJANDRO MUOZ G. FundacinInternacionalParaElReencuentro",
         "Media and Entertainment",
         "The Colombian journalist ALEJANDRO MUOZ GARZON, creator of the FOUNDATION INTERNATIONAL FOR THE REUNION, www.funreencuentros.com/ pioneered national television to start with conducting historical research encounters, some of which were and are issued by national channels and Rafael Poveda foreign and TV, Caracol TV, Tevecine, JES Productions, Univision and Telemundo. Equally unique is the pioneer and promoter of desaprecidos search activities in media and packaging of consumer products, including milk cartons \"ALPINA\", campaign between 2001 and 2005 in Colombia; period during which about Colombian one hundred patients disappeared, they returned to their homes with the publication of photographs in dairy packaging. El periodista Colombiano ALEJANDRO MUOZ GARZON, gestor de la FUNDACION INTERNACIONAL PARA EL REENCUENTRO, www.funreencuentros.com/ es pionero en la televisin nacional al iniciar con sus investigaciones la realizacin de histricos reencuentros, algunos de los cuales fueron y son emitidos por canales nacionales y extranjeros como Rafael Poveda Televisin, Caracol TV, Tevecine, Producciones JES, Univisin y Telemundo. Igualmente es pionero y nico impulsador de actividades de bsqueda de desaprecidos en medios de comunicacin y empaques de productos de consumo masivo, entre ellos en las cajas de leche ALPINA, campaa realizada entre los aos 2001 y 2005 en Colombia; periodo durante el cual, cerca de un centenar de Colombianos enfermos desaparecidos, regresaron a sus hogares gracias a la publicacin de fotografias en los empaques lacteos.",
         [
          "Investigo el paradero de Padres, Madres, Hermanos e Hijos de origen latinoamericano que se han desaparecido por muchos aos y por razones de violencia intrafamiliar o adopcin y una vez ubicados y asistidos sicoafectiva y mdicamente tras la aceptacin y comprobacion cientfica (Test ADN s es necesario) procedemos a ayudarlos en el logro del abrazo tan esperado",
          "As benefactor and volunteer for the Foundation for the Reunion, www.funreencuentros.com/ I have witnessed for more than twelve years the outstanding work of this Foundation located in Bogota, Colombia. This institution was created to reacquaint healthy and successfully adopted Colombian individuals with their biological families, through a process of psycho-emotional adjustment accompanied by professionals in the field of documentary research, tracking, location and preparation for the reunion. During this time, while gaining experience on the issue of family separation and reunion, this institution that I highly recommend has performed an average of 10,669 reunions of Colombians lost from their families. Among them, 3,599 reunions have been made for Colombian adopted who sought",
          "REPORTERO Y PRESENTADOR DE NOTAS PERIODISTICAS CON TINTE HUMORISTICO COMPROBANDO TEMAS Y REFRANES POPULARES COMO: \"DE TAL PALO TAL ASTILLA\" \"MATRIMONIO Y MORTAJA DEL CIELO BAJA\" \"LAS COSAS SE PARECEN A SUS DUENOS\" ETC. EN SABADOS FELICES SECCION LAS AVENTURAS DEL MACHORR"
         ],
         "For over a decade, my passion for bridging familial connections has driven me as a volunteer at the Foundation for the Reunion, where I've witnessed the transformative power of reuniting long-lost loved ones. My experience in uncovering their whereabouts and facilitating their psychoemotional recovery has honed my skills in documentary research, tracking, and location. Through the lens of popular sayings, I've explored the human condition as a reporter and presenter for Sbado Felices, delving into the themes of family bonds, destiny, and personal growth. These experiences have instilled in me a deep understanding of the emotional complexities and the profound impact of reconnecting families. I am eager to translate these skills into the dynamic realm of Media and Entertainment, where I can utilize my storytelling abilities and research acumen to engage and inspire audiences through compelling narratives that celebrate the resilience of the human spirit and the indomitable power of family connections."
        ],
        [
         "ALLISON CHUNG",
         "Education and Training",
         "Experienced Accounts Payable Specialist with a demonstrated history of working in the primary/secondary education industry. Skilled in Nonprofit Organizations, Microsoft Word, Team Building, Fundraising, and Leadership. Strong operations professional with a Masters degree (M.S) focused in Human Service Counseling: Marriage and Family from Liberty University.",
         [
          "Performs difficult clerical tasks involving the application of bookkeeping principles and account keeping practices in order to maintain the financial accounts and records. Prepares and inputs accounting data into the Oracle financial system. Reviews invoice",
          "Responsible for all aspects of the accounts payable process.Tracked the budget on a weekly basis during the accounts payable process. Responsible for reconciliation of all credit card payments. Reviewed and processed all expense reports for the company. Prepared billing invoices. Updated employee records. Responsible for new hire orientation. Responsible for all aspects of 1099 preparation. Assisted in payroll processes. Assisted in other fiscal and human resource duties as assigned.",
          "Prepared and entered all lockbox payments into the automated accounting system.Posted payment batches to the correct accounting period and prepared, filed and distributed final reports. Reviewed and processed expense reports and refund requests for appropriate authorizations and assigned the correct accounting entry.Prepared and entered journal entri"
         ],
         "I am a highly skilled and experienced professional with a proven track record in Education and Training. Throughout my career, I have consistently exceeded expectations in various roles within the industry, leveraging my expertise in financial management, accounting principles, and human resource administration. As a former accounts payable specialist responsible for all aspects of the process, I meticulously tracked budgets, reconciled credit card payments, and processed expense reports. My ability to maintain accurate financial records and ensure compliance with industry standards is a testament to my unwavering attention to detail. Furthermore, I have extensive experience in payroll processing, new hire orientation, and 1099 preparation, demonstrating my comprehensive understanding of human resource functions. My versatility and adaptability have enabled me to provide support in both fiscal and human resource capacities, showcasing my commitment to efficiency and teamwork. I am confident that I can bring my knowledge and skills to your Education and Training organization and make a significant contribution to its success."
        ],
        [
         "ASHLEA HERRING",
         "Retail and Consumer Goods",
         "I am an outgoing fun people loving person.",
         [
          "Calling the Client, picking up the client taking the client to their destination, cleaning the limo or party bus and pre trip and post trip"
         ],
         "Throughout my tenure in the retail and consumer goods industry, I have consistently exceeded expectations in providing exceptional customer service and maintaining the highest standards of excellence. As a Limo/Party Bus Driver, I excelled in ensuring the safety, comfort, and satisfaction of clients. I proactively called clients, punctually picked them up, and safely transported them to their destinations. Maintaining a pristine appearance of the vehicles was paramount, as I meticulously cleaned and inspected both limos and party buses before and after each trip. My keen attention to detail and commitment to providing a seamless experience have earned me a reputation for reliability and professionalism. I am confident that my skills and experience would make me a valuable asset to any organization seeking a dedicated and customer-focused individual in the retail and consumer goods sector."
        ],
        [
         "Aaron Acuna",
         "Government and Public Policy",
         "Have worked State/Government jobs since 2018. Good with data entry in Excel and copy writing/editing in Word. Have extensively used Teams and Outlook but am proficient in Google systems as well (Calendars, Sheets, etc.). From 2016-2018 I worked as a student employee for the University of Alaska, Anchorage (UAA) in various jobs, including as (1) a Library Intern (designing posters, working the front desk), (2) an English Department Intern (writing the website's scholarships page), (3) an Information Desk Clerk for the Learning Center, and (4) an English Tutor (proofreading/editing student papers, running the ESL Conversation Group). I was the unofficial records custodian for Alaska Occupational Safety & Health (AKOSH, or Alaska OSHA) from 2018-2020 in which I handled confidential records requests and requests for information under the Alaska Public Records Act (APRA). At that time, I took an Excel 101 course as voluntary job training. From 2020-2022 I spent most of my job at the State Ombudsman's Office copy-writing nuanced letters going out to various types of clients, including confidential responses to citizens and other state agencies. Since 2022 I've been working with the State of Alaska's FEMA Team in the Department of Health, in which I track and enter budget data in extensive Excel spreadsheets",
         [
          "FEMA Team data reviewer - Remote date entry, file organization, team meetings"
         ],
         "With a proven track record as a FEMA Team Data Reviewer, I bring a comprehensive skillset to government and public policy roles. My expertise in remote data entry, file organization, and team collaboration has honed my ability to handle sensitive information and contribute to high-priority initiatives. I am adept at extracting critical data, maintaining meticulous records, and ensuring efficient workflow. Moreover, my participation in team meetings has strengthened my communication and coordination abilities, enabling me to work effectively in a diverse and results-oriented environment. I am confident that my experience and commitment to accuracy, confidentiality, and public service will make me a valuable asset to any organization seeking to advance its mission in the government and public policy sector."
        ],
        [
         "Aaron Baltz",
         "Manufacturing",
         "Pursuing a career in non-destructive testing and aerospace inspection.",
         [
          "Electro-Mechanical Inspection",
          "Tear down, evaluate and repair aircraft heavy engine nacelles and reversers."
         ],
         "Seeking a Manufacturing role where I can leverage my expertise in Electro-Mechanical Inspection, gained through meticulously evaluating and repairing aircraft heavy engine nacelles and reversers. My proficiency in troubleshooting and repairing complex mechanical systems translates seamlessly to the manufacturing environment, enabling me to identify and resolve production-related issues promptly and effectively. With a keen eye for detail, I possess the ability to assess equipment functionality, diagnose faults, and implement corrective actions, ensuring optimal operational efficiency and minimizing downtime. Additionally, my familiarity with industry-specific tools and methodologies enables me to work collaboratively with production teams to optimize processes and enhance quality control measures, ultimately contributing to enhanced productivity and cost reduction within the manufacturing sector."
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "meta_industry",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "about",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "descriptions",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "generated_description",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "df_llm = df_llm.dropna()\n",
    "grouped_df_llm = df_llm.groupBy('name','meta_industry','about').agg(collect_list('description').alias('descriptions'))\n",
    "def get_generate_prompt(content, industry):\n",
    "    #prompt = f\"Extract key keywords or phrases from the following text: {content}\"\n",
    "    #prompt = prompt + \"\"\"\n",
    "    #1. Identify and list the most important keywords or key phrases in the text. These keywords should capture the main topics, concepts, or subjects of work #experience and job skills discussed in the text.\n",
    "    #2. If there are subtopics or secondary themes mentioned in the text, list them as well.\n",
    "    #3. Include the exact text span or sentence where each keyword or phrase is found in the original text.\n",
    "    #4. Consider the context, relevance, and frequency of the keywords when determining their significance.\n",
    "    #\"\"\"\n",
    "    content_txt = \" | \".join(content)\n",
    "    #prompt = f\"Briefly write the description that will maximize your chances of being hired based on the following about-me section: {content}. \"\n",
    "    \n",
    "    desired_length = about_length_dict[industry]\n",
    "    prompt = f\"Your task is to generate a new 'about' paragraph of average length of {desired_length}, take into account that the job industry is {industry}, and build upon the provided list of past job experience: {content_txt}\"\n",
    "    prompt = prompt + \"\"\"\n",
    "    1.The paragraph should make a good impression that will maximize the chances of getting hired.\n",
    "    2. Focus on closely aligning with the original paragraph's themes and data, highlighting your key strengths and experiences in a balanced and realistic #manner.\n",
    "    3.Ensure that your new paragraph maintains coherence and relevance to the job search context, presenting yourself in the best possible light without #overstating your qualifications.\n",
    "\n",
    "    \"\"\"\n",
    "    prompt = prompt + f\"4. Try to incorporate key words from the given past job experience, that are related to the {industry} industry.\"\n",
    "    \n",
    "    return prompt\n",
    "    \n",
    "def text_generator(text, industry):\n",
    "    # agent prompt\n",
    "    prompt = get_generate_prompt(text, industry)\n",
    "\n",
    "    # use the Gemini-Pro model generate content\n",
    "    genetared_text = model.generate_content(prompt)\n",
    "    \n",
    "    return genetared_text\n",
    "\n",
    "GEMINI_API_KEY = \"AIzaSyAkMU-79EiBfUWbsjjai0CgoQC1bbCH8pM\" # \"input(\"INSERT YOUR GOOGLE API KEY PLEASE:\")\"\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "dataCollect=grouped_df_llm.limit(10).rdd.toLocalIterator()\n",
    "# Convert the iterator to a list\n",
    "dataCollect = list(dataCollect)\n",
    "\n",
    "# Apply the generate_row function to the description column of each row\n",
    "new_data = [Row(**{**row.asDict(), 'generated_description': text_generator(row['descriptions'], row['meta_industry']).text}) for row in dataCollect]\n",
    "\n",
    "# Convert the list back to an RDD\n",
    "new_rdd = spark.sparkContext.parallelize(new_data)\n",
    "\n",
    "generated_desc_df = new_rdd.toDF()\n",
    "generated_desc_df.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Project",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
